<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="本人喜好源码阅读，得益于目前的工作环境，对流式计算主流的框架较为了解，平常热衷于阅读一些内核的源码，希望分享出来与大家互动和交流，至于生活感悟，心灵鸡汤神马的就免了吧~"><title>Flink源码分析-基本组件和逻辑计划 | 玉兆的博客</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/5.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Flink源码分析-基本组件和逻辑计划</h1><a id="logo" href="/.">玉兆的博客</a><p class="description">心如止水</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Flink源码分析-基本组件和逻辑计划</h1><div class="post-meta">Dec 3, 2016<span> | </span><span class="category"><a href="/categories/Streaming/">Streaming</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-disqus-identifier="2016/12/03/Flink基本组件和逻辑计划/" href="/2016/12/03/Flink基本组件和逻辑计划/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#概要和背景"><span class="toc-number">1.</span> <span class="toc-text">概要和背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#核心组件介绍"><span class="toc-number">2.</span> <span class="toc-text">核心组件介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#作业提交流程分析"><span class="toc-number">2.1.</span> <span class="toc-text">作业提交流程分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#配置加载"><span class="toc-number">2.1.1.</span> <span class="toc-text">配置加载</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#参数解析"><span class="toc-number">2.1.2.</span> <span class="toc-text">参数解析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#flink集群的构建"><span class="toc-number">2.1.3.</span> <span class="toc-text">flink集群的构建</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#集群类型的解析"><span class="toc-number">2.1.3.1.</span> <span class="toc-text">集群类型的解析</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#集群部署"><span class="toc-number">2.1.3.2.</span> <span class="toc-text">集群部署</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#客户端逻辑计划"><span class="toc-number">2.2.</span> <span class="toc-text">客户端逻辑计划</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#初步逻辑计划-StreamGraph-的生成"><span class="toc-number">2.2.1.</span> <span class="toc-text">初步逻辑计划 StreamGraph 的生成</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#优化的逻辑计划-JobGraph-的生成"><span class="toc-number">2.2.2.</span> <span class="toc-text">优化的逻辑计划 JobGraph 的生成</span></a></li></ol></li></ol></li></ol></div></div><div class="post-content"><h2 id="概要和背景"><a href="#概要和背景" class="headerlink" title="概要和背景"></a>概要和背景</h2><p><em>flink</em>是一个被誉为 <em>the 4th G</em> 的计算框架，不同的框架特性及其代表项目列表如下：</p>
<table>
<thead>
<tr>
<th>第一代</th>
<th>第二代</th>
<th>第三代</th>
<th>第四代</th>
</tr>
</thead>
<tbody>
<tr>
<td>Batch</td>
<td><strong>Batch</strong> <strong>Interactive</strong></td>
<td><strong>Batch</strong> <strong>Interactive</strong> <strong>Near-Real-Time</strong> <strong>Interative-processing</strong></td>
<td><strong>Hybrid</strong> <strong>Interactive</strong> <strong>Real-Time-Streaming</strong> <strong>Native-Iterative-processing</strong></td>
</tr>
<tr>
<td></td>
<td>DAG Dataflows</td>
<td>RDD</td>
<td>Cyclic Dataflows</td>
</tr>
<tr>
<td>Hadoop MapReduce</td>
<td>TEZ</td>
<td>Spark</td>
<td>Flink</td>
</tr>
</tbody>
</table>
<p>本文主要介绍<em>flink</em>的核心组件以及逻辑计划的生成过程</p>
<p><em>参考代码分支 flink-1.1.2</em></p>
<h2 id="核心组件介绍"><a href="#核心组件介绍" class="headerlink" title="核心组件介绍"></a>核心组件介绍</h2><p><em>这里只介绍 on yarn 模式下的组件</em></p>
<p><em>flink</em> 的 on yarn 模式支持两种不同的类型：</p>
<ol>
<li>单作业单集群</li>
<li>多作业单集群</li>
</ol>
<p>首先介绍 <em>单作业单集群</em> 的架构，单作业单集群下一个正常的 <em>flink</em> 程序会拥有以下组件</p>
<hr>
<p>job Cli: 非 detatched 模式下的客户端进程，用以获取 yarn Application Master 的运行状态并将日志输出掉终端</p>
<p>JobManager[JM]: 负责作业的运行时计划 ExecutionGraph 的生成、物理计划生成和作业调度</p>
<p>TaskManager[TM]: 负责被分发 task 的执行、心跳/状态上报、资源管理</p>
<hr>
<p>整体的架构大致如下图所示：</p>
<img src="/2016/12/03/Flink基本组件和逻辑计划/flink-on-yarn-arch.png" alt="flink on yarn" title="flink on yarn">
<p>下面将以一次 Job 的提交过程描述 <em>flink</em> 的各组件的作用及协同</p>
<h3 id="作业提交流程分析"><a href="#作业提交流程分析" class="headerlink" title="作业提交流程分析"></a>作业提交流程分析</h3><p>单作业单集群模式下，一个作业会启动一个 JM，并依据用户的参数传递启动相应数量的 TM，每个 TM 运行在 yarn 的一个 container 中，</p>
<p>一个通常的 flink on yarn 提交命令：<br><code>./bin/flink run -m yarn-cluster -yn 2 -j flink-demo-1.0.0-with-dependencies.jar —ytm 1024 -yst 4 -yjm 1024 —yarnname flink_demo_waimai_e</code><br><em>flink</em> 在收到这样一条命令后会首先通过 Cli 获取 flink 的配置，并解析命令行参数。</p>
<h4 id="配置加载"><a href="#配置加载" class="headerlink" title="配置加载"></a>配置加载</h4><p><code>CliFrontend.java</code> 是 flink 提交作业的入口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//CliFrontend line144</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">CliFrontend</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">   <span class="keyword">this</span>(getConfigurationDirectoryFromEnv());</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里会尝试加载 conf 文件夹下的所有 yaml 文件，配置文件的命名并没有强制限制</p>
<h4 id="参数解析"><a href="#参数解析" class="headerlink" title="参数解析"></a>参数解析</h4><p>解析命令行参数的第一步是路由用户的命令，然后交由<code>run</code>方法去处理</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//CliFrontend line993</span></div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">return</span> SecurityUtils.runSecured(<span class="keyword">new</span> SecurityUtils.FlinkSecuredRunner&lt;Integer&gt;() &#123;</div><div class="line">	    <span class="function">Override</span></div><div class="line">	    <span class="keyword">public</span> Integer <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</div><div class="line">	        <span class="keyword">return</span> CliFrontend.<span class="keyword">this</span>.run(params);</div><div class="line">		&#125;);</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">		<span class="keyword">return</span> handleError(e);</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<p>接下来是程序参数设置过程，<em>flink</em> 将 jar包路径和参数配置封装成了 <code>PackagedProgram</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//CliFrontend line223</span></div><div class="line">PackagedProgram program;</div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">   LOG.info(<span class="string">"Building program from JAR file"</span>);</div><div class="line">   program = buildProgram(options);</div><div class="line">&#125;</div><div class="line"><span class="keyword">catch</span> (Throwable t) &#123;</div><div class="line">   <span class="keyword">return</span> handleError(t);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="flink集群的构建"><a href="#flink集群的构建" class="headerlink" title="flink集群的构建"></a>flink集群的构建</h4><h5 id="集群类型的解析"><a href="#集群类型的解析" class="headerlink" title="集群类型的解析"></a>集群类型的解析</h5><p>获取参数后下一步就是集群的构建和部署，flink 通过 两个不同的 <code>CustomCommandLine</code> 来实现不同集群模式的解析，分别是 <code>FlinkYarnSessionCli</code>和 <code>DefaultCLI</code> 【吐槽一下 flink 类名的命名规范】解析命令行参数</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//CliFrontend line125</span></div><div class="line"><span class="keyword">static</span> &#123;</div><div class="line">   <span class="comment">/** command line interface of the YARN session, with a special initialization here</span></div><div class="line">    *  to prefix all options with y/yarn. */</div><div class="line">   loadCustomCommandLine(<span class="string">"org.apache.flink.yarn.cli.FlinkYarnSessionCli"</span>, <span class="string">"y"</span>, <span class="string">"yarn"</span>);</div><div class="line">   customCommandLine.add(<span class="keyword">new</span> DefaultCLI());</div><div class="line">&#125;</div><div class="line">...</div><div class="line"><span class="comment">//line882 这里将决定Cli的类型</span></div><div class="line">CustomCommandLine&lt;?&gt; activeCommandLine = getActiveCustomCommandLine(options.getCommandLine());</div></pre></td></tr></table></figure>
<p>那么什么时候解析成 Yarn Cluster 什么时候解析成 Standalone 呢？由于<code>FlinkYarnSessionCli</code>被优先添加到<code>customCommandLine</code>,所以会先触发下面这段逻辑</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//FlinkYarnSessionCli line469</span></div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isActive</span><span class="params">(CommandLine commandLine, Configuration configuration)</span> </span>&#123;</div><div class="line">   String jobManagerOption = commandLine.getOptionValue(ADDRESS_OPTION.getOpt(), <span class="keyword">null</span>);</div><div class="line">   <span class="keyword">boolean</span> yarnJobManager = ID.equals(jobManagerOption);</div><div class="line">   <span class="keyword">boolean</span> yarnAppId = commandLine.hasOption(APPLICATION_ID.getOpt());</div><div class="line">   <span class="keyword">return</span> yarnJobManager || yarnAppId || loadYarnPropertiesFile(commandLine, configuration) != <span class="keyword">null</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上面可以看出如果用户传入了 <code>-m</code>参数或者<code>application id</code>或者配置了yarn properties 文件，则启动yarn cluster模式，否则是Standalone模式的集群</p>
<h5 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h5><p>flink通过<code>YarnClusterDescriptor</code>来描述yarn集群的部署配置，具体对应的配置文件为<code>flink-conf.yaml</code>，通过下面这段逻辑触发集群部署：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//AbstractYarnClusterDescriptor line372</span></div><div class="line"><span class="comment">/**</span></div><div class="line"> * This method will block until the ApplicationMaster/JobManager have been</div><div class="line"> * deployed on YARN.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">protected</span> YarnClusterClient <span class="title">deployInternal</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div></pre></td></tr></table></figure>
<p>大致列下过程：</p>
<ul>
<li>check yarn 集群队列资源是否满足请求</li>
<li>设置 AM Context、启动命令、submission context</li>
<li>如果开启高可用模式【通过反射调用 submission context 的两个方法修改属性】 keepContainersMethod    attemptFailuresValidityIntervalMethod 【和 Hadoop 的版本有关】第一个属性表示应用重试时是否保留 AM container，第二个属性表示 指定 间隔时间之内应用允许失败重启的次数</li>
<li>上传 用户 jar、flink-conf.yaml、lib 目录下所有的 jar 包、logback log4j配置文件 到 HDFS</li>
<li>通过 yarn client submit am context</li>
<li>将yarn client 及相关配置封装成 YarnClusterClient 返回</li>
</ul>
<p>真正在 AM 中运行的主类是 <code>YarnApplicationMasterRunner</code>，它的 <code>run</code>方法做了如下工作：</p>
<ul>
<li>启动JobManager ActorSystem</li>
<li>启动 flink ui</li>
<li>启动<code>YarnFlinkResourceManager</code>来负责与yarn的ResourceManager交互，管理yarn资源</li>
<li>启动 actor System supervise 进程</li>
</ul>
<p>到这里 JobManager 已经启动起来，那么 TaskManager是什么时候起动的呢？</p>
<p>在 <code>YarnFlinkResourceManager</code>启动的时候会预先执行一段逻辑【Akka actor的preStart方法】：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preStart</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="comment">// we start our leader retrieval service to make sure we get informed</span></div><div class="line">        <span class="comment">// about JobManager leader changes</span></div><div class="line">        leaderRetriever.start(<span class="keyword">new</span> LeaderRetrievalListener() &#123;</div><div class="line"></div><div class="line">		    <span class="meta">@Override</span></div><div class="line">		    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">notifyLeaderAddress</span><span class="params">(String leaderAddress, UUID leaderSessionID)</span> </span>&#123;</div><div class="line">		        self().tell(</div><div class="line">						<span class="keyword">new</span> NewLeaderAvailable(leaderAddress, leaderSessionID),</div><div class="line">						ActorRef.noSender());</div><div class="line">		    &#125;</div></pre></td></tr></table></figure>
<p>这段逻辑会先尝试获取 JobManager 的地址并给自己发送一个路由消息<code>NewLeaderAvailable</code>，然后<code>YarnFlinkResourceManager</code>会把自己注册到 <code>JobManager</code> 中，接着<code>JobManager</code>会发送一个回调命令：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//JobManager line358</span></div><div class="line">sender ! decorateMessage(<span class="keyword">new</span> <span class="type">RegisterResourceManagerSuccessful</span>(self, taskManagerResources))</div></pre></td></tr></table></figure>
<p>接着会触发这样一段逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//FlinkResourceManager line555</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">checkWorkersPool</span><span class="params">()</span> </span>&#123;</div><div class="line">   <span class="keyword">int</span> numWorkersPending = getNumWorkerRequestsPending();</div><div class="line">   <span class="keyword">int</span> numWorkersPendingRegistration = getNumWorkersPendingRegistration();</div><div class="line"></div><div class="line">   <span class="comment">// sanity checks</span></div><div class="line">   Preconditions.checkState(numWorkersPending &gt;= <span class="number">0</span>,</div><div class="line">      <span class="string">"Number of pending workers should never be below 0."</span>);</div><div class="line">   Preconditions.checkState(numWorkersPendingRegistration &gt;= <span class="number">0</span>,</div><div class="line">      <span class="string">"Number of pending workers pending registration should never be below 0."</span>);</div><div class="line"></div><div class="line">   <span class="comment">// see how many workers we want, and whether we have enough</span></div><div class="line">   <span class="keyword">int</span> allAvailableAndPending = startedWorkers.size() +</div><div class="line">      numWorkersPending + numWorkersPendingRegistration;</div><div class="line"></div><div class="line">   <span class="keyword">int</span> missing = designatedPoolSize - allAvailableAndPending;</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (missing &gt; <span class="number">0</span>) &#123;</div><div class="line">      requestNewWorkers(missing);</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>将所有的 TS 起动起来，这样一个 flink 集群便构建出来了。下面附图解释下这个流程：</p>
<img src="/2016/12/03/Flink基本组件和逻辑计划/flink-cluster-start-flow.png" alt="flink-cluster-start-flow" title="flink-cluster-start-flow">
<ol>
<li>flink cli 解析本地环境配置，启动 <code>ApplicationMaster</code></li>
<li>在 <code>ApplicationMaster</code> 中启动 <code>JobManager</code></li>
<li>在 <code>ApplicationMaster</code> 中启动<code>YarnFlinkResourceManager</code></li>
<li><code>YarnFlinkResourceManager</code>给<code>JobManager</code>发送注册信息</li>
<li><code>YarnFlinkResourceManager</code>注册成功后，<code>JobManager</code>给<code>YarnFlinkResourceManager</code>发送注册成功信息</li>
<li><code>YarnFlinkResourceManage</code>知道自己注册成功后像<code>ResourceManager</code>申请和<code>TaskManager</code>数量对等的 container</li>
<li>在container中启动<code>TaskManager</code></li>
<li><code>TaskManager</code>将自己注册到<code>JobManager</code>中</li>
</ol>
<p><em>接下来便是程序的提交和运行</em></p>
<p>程序在<code>CliFrontend</code>中被提交后，会触发这样一段逻辑</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ClusterClient 304</span></div><div class="line">	<span class="function"><span class="keyword">public</span> JobSubmissionResult <span class="title">run</span><span class="params">(PackagedProgram prog, <span class="keyword">int</span> parallelism)</span></span></div><div class="line">			<span class="keyword">throws</span> ProgramInvocationException</div><div class="line">	&#123;</div><div class="line">		Thread.currentThread().setContextClassLoader(prog.getUserCodeClassLoader());</div><div class="line">		...</div><div class="line">		<span class="keyword">else</span> <span class="keyword">if</span> (prog.isUsingInteractiveMode()) &#123;</div><div class="line">			LOG.info(<span class="string">"Starting program in interactive mode"</span>);</div><div class="line">			ContextEnvironmentFactory factory = <span class="keyword">new</span> ContextEnvironmentFactory(<span class="keyword">this</span>, prog.getAllLibraries(),</div><div class="line">					prog.getClasspaths(), prog.getUserCodeClassLoader(), parallelism, isDetached(),</div><div class="line">					prog.getSavepointPath());</div><div class="line">			ContextEnvironment.setAsContext(factory);</div><div class="line"></div><div class="line">			<span class="keyword">try</span> &#123;</div><div class="line">				<span class="comment">// invoke main method</span></div><div class="line">				prog.invokeInteractiveModeForExecution();</div><div class="line">				...</div><div class="line">			&#125;</div><div class="line">			<span class="keyword">finally</span> &#123;</div><div class="line">				ContextEnvironment.unsetContext();</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">else</span> &#123;</div><div class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"PackagedProgram does not have a valid invocation mode."</span>);</div><div class="line">		&#125;</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<p>注意到有一段<code>prog.invokeInteractiveModeForExecution()</code>，这是客户端生成初步逻辑计划的核心逻辑，下面将详细介绍</p>
<h3 id="客户端逻辑计划"><a href="#客户端逻辑计划" class="headerlink" title="客户端逻辑计划"></a>客户端逻辑计划</h3><p>上面提到<code>prog.invokeInteractiveModeForExecution()</code>这段逻辑会触发客户端逻辑计划的生成，那么是怎样一个过程呢？其实这里只是调用了用户jar包的主函数，真正的触发生成过程由用户代码的执行来完成。例如用户写了这样一段 flink 代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">object FlinkDemo extends App with Logging&#123;</div><div class="line">  <span class="function">override def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>=&#123;</div><div class="line">    val properties = <span class="keyword">new</span> Properties</div><div class="line">    properties.setProperty(<span class="string">"bootstrap.servers"</span>, DemoConfig.kafkaBrokerList)</div><div class="line"></div><div class="line"> properties.setProperty(<span class="string">"zookeeper.connect"</span>,<span class="string">"host01:2181,host02:2181,host03:2181/kafka08"</span>)</div><div class="line">    properties.setProperty(<span class="string">"group.id"</span>, <span class="string">"flink-demo-waimai-e"</span>)</div><div class="line"></div><div class="line">    val env = StreamExecutionEnvironment.getExecutionEnvironment</div><div class="line">    env.enableCheckpointing(<span class="number">5000L</span>, CheckpointingMode.EXACTLY_ONCE) <span class="comment">//checkpoint every 5 seconds.</span></div><div class="line">    val stream = env.addSource(<span class="keyword">new</span> FlinkKafkaConsumer08[String](<span class="string">"log.waimai_e"</span>, <span class="keyword">new</span> SimpleStringSchema, properties)).setParallelism(<span class="number">2</span>)</div><div class="line">    val counts = stream.name(<span class="string">"log.waimai_e"</span>).map(toPoiIdTuple(_)).filter(_._2 != <span class="keyword">null</span>)</div><div class="line">      .keyBy(<span class="number">0</span>)</div><div class="line">      .timeWindow(Time.seconds(<span class="number">5</span>))</div><div class="line">      .sum(<span class="number">1</span>)</div><div class="line"></div><div class="line">    counts.addSink(sendToKafka(_))</div><div class="line">    env.execute()</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>注意到这样一段<code>val env = StreamExecutionEnvironment.getExecutionEnvironment</code>，这段代码会获取客户端的环境配置，它首先会转到这样一段逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamExecutionEnvironment 1256</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> StreamExecutionEnvironment <span class="title">getExecutionEnvironment</span><span class="params">()</span> </span>&#123;</div><div class="line">   <span class="keyword">if</span> (contextEnvironmentFactory != <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">return</span> contextEnvironmentFactory.createExecutionEnvironment();</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="comment">// because the streaming project depends on "flink-clients" (and not the other way around)</span></div><div class="line">   <span class="comment">// we currently need to intercept the data set environment and create a dependent stream env.</span></div><div class="line">   <span class="comment">// this should be fixed once we rework the project dependencies</span></div><div class="line"></div><div class="line">   ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</div></pre></td></tr></table></figure>
<p><code>ExecutionEnvironment.getExecutionEnvironment();</code>获取环境的逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ExecutionEnvironment line1137</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutionEnvironment <span class="title">getExecutionEnvironment</span><span class="params">()</span> </span>&#123;</div><div class="line">   <span class="keyword">return</span> contextEnvironmentFactory == <span class="keyword">null</span> ?</div><div class="line">         createLocalEnvironment() : contextEnvironmentFactory.createExecutionEnvironment();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里的<code>contextEnvironmentFactory</code>是一个静态成员，早在<code>ContextEnvironment.setAsContext(factory)</code>已经触发过初始化了，其中包含了如下的环境信息:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ContextEnvironmentFactory line51</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">ContextEnvironmentFactory</span><span class="params">(ClusterClient client, List&lt;URL&gt; jarFilesToAttach,</span></span></div><div class="line">      List&lt;URL&gt; classpathsToAttach, ClassLoader userCodeClassLoader, <span class="keyword">int</span> defaultParallelism,</div><div class="line">      <span class="keyword">boolean</span> isDetached, String savepointPath)</div><div class="line">&#123;</div><div class="line">   <span class="keyword">this</span>.client = client;</div><div class="line">   <span class="keyword">this</span>.jarFilesToAttach = jarFilesToAttach;</div><div class="line">   <span class="keyword">this</span>.classpathsToAttach = classpathsToAttach;</div><div class="line">   <span class="keyword">this</span>.userCodeClassLoader = userCodeClassLoader;</div><div class="line">   <span class="keyword">this</span>.defaultParallelism = defaultParallelism;</div><div class="line">   <span class="keyword">this</span>.isDetached = isDetached;</div><div class="line">   <span class="keyword">this</span>.savepointPath = savepointPath;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其中的 client 就是上面生成的 <code>YarnClusterClient</code>，其它的意思较明显，就不多做解释了。</p>
<p>用户在执行<code>val env = StreamExecutionEnvironment.getExecutionEnvironment</code>这样一段逻辑后会得到一个<code>StreamContextEnvironment</code>，其中封装了 streaming 的一些执行配置 【buffer time out等】，另外保存了上面提到的 <code>ContextEnvironmen</code>t 的引用。</p>
<p>到这里关于 streaming 需要的执行环境信息已经设置完成。</p>
<h4 id="初步逻辑计划-StreamGraph-的生成"><a href="#初步逻辑计划-StreamGraph-的生成" class="headerlink" title="初步逻辑计划 StreamGraph 的生成"></a>初步逻辑计划 StreamGraph 的生成</h4><p>接下来用户代码执行到<code>val stream = env.addSource(new FlinkKafkaConsumer08</code>，这段逻辑实际会生成一个<code>DataStream</code>抽象，<code>DataStream</code>是flink关于streaming抽象的最核心抽象，后续所有的算子转换都会在<code>DataStream</code>上来完成，上面的<code>addSource</code>操作会触发下面这段逻辑:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> &lt;OUT&gt; <span class="function">DataStreamSource&lt;OUT&gt; <span class="title">addSource</span><span class="params">(SourceFunction&lt;OUT&gt; function, String sourceName, TypeInformation&lt;OUT&gt; typeInfo)</span> </span>&#123;</div><div class="line"></div><div class="line">   <span class="keyword">if</span>(typeInfo == <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">if</span> (function <span class="keyword">instanceof</span> ResultTypeQueryable) &#123;</div><div class="line">         typeInfo = ((ResultTypeQueryable&lt;OUT&gt;) function).getProducedType();</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">         <span class="keyword">try</span> &#123;</div><div class="line">            typeInfo = TypeExtractor.createTypeInfo(</div><div class="line">                  SourceFunction.class,</div><div class="line">                  function.getClass(), <span class="number">0</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</div><div class="line">         &#125; <span class="keyword">catch</span> (<span class="keyword">final</span> InvalidTypesException e) &#123;</div><div class="line">            typeInfo = (TypeInformation&lt;OUT&gt;) <span class="keyword">new</span> MissingTypeInfo(sourceName, e);</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">boolean</span> isParallel = function <span class="keyword">instanceof</span> ParallelSourceFunction;</div><div class="line"></div><div class="line">   clean(function);</div><div class="line">   StreamSource&lt;OUT, ?&gt; sourceOperator;</div><div class="line">   <span class="keyword">if</span> (function <span class="keyword">instanceof</span> StoppableFunction) &#123;</div><div class="line">      sourceOperator = <span class="keyword">new</span> StoppableStreamSource&lt;&gt;(cast2StoppableSourceFunction(function));</div><div class="line">   &#125; <span class="keyword">else</span> &#123;</div><div class="line">      sourceOperator = <span class="keyword">new</span> StreamSource&lt;&gt;(function);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">return</span> <span class="keyword">new</span> DataStreamSource&lt;&gt;(<span class="keyword">this</span>, typeInfo, sourceOperator, isParallel, sourceName);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简要总结下上面的逻辑：</p>
<ul>
<li>获取数据源 source 的 output 信息 TypeInformation</li>
<li>生成 StreamSource sourceOperator</li>
<li>生成 DataStreamSource【封装了 sourceOperator】，并返回</li>
<li>将 StreamTransformation 添加到算子列表 transformations 中【只有 转换 transform 操作才会添加算子，其它都只是暂时做了 transformation 的叠加封装】</li>
<li>后续会在 DataStream 上做操作</li>
</ul>
<p>该输出<code>DataStreamSource</code>继承自<code>SingleOutputStreamOperator</code>具体的继承关系如下：</p>
<img src="/2016/12/03/Flink基本组件和逻辑计划/flink-datastream-extend.png" alt="flink-datastream-extend" title="flink-datastream-extend">
<p>而生成的 StreamSource operator 走的是另一套继承接口：</p>
<img src="/2016/12/03/Flink基本组件和逻辑计划/stream-operator-extend.png" alt="stream-operator-extend" title="stream-operator-extend">
<p>DataStreamSource 是一个 DataStream <strong>数据流</strong>抽象，StreamSource 是一个 StreamOperator <strong>算子</strong>抽象，在 flink 中一个 DataStream 封装了一次数据流转换，一个 StreamOperator 封装了一个函数接口，比如 map、reduce、keyBy等。<em>关于算子的介绍会另起一节：flink算子的声明周期</em></p>
<p>可以看到在 DataStream 上可以进行一系列的操作(map filter 等)，来看一个常规操作比如 map 会发生什么：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//DataStream line503</span></div><div class="line"><span class="keyword">public</span> &lt;R&gt; <span class="function">SingleOutputStreamOperator&lt;R&gt; <span class="title">map</span><span class="params">(MapFunction&lt;T, R&gt; mapper)</span> </span>&#123;</div><div class="line"></div><div class="line">   TypeInformation&lt;R&gt; outType = TypeExtractor.getMapReturnTypes(clean(mapper), getType(),</div><div class="line">         Utils.getCallLocationName(), <span class="keyword">true</span>);</div><div class="line"></div><div class="line">   <span class="keyword">return</span> transform(<span class="string">"Map"</span>, outType, <span class="keyword">new</span> StreamMap&lt;&gt;(clean(mapper)));</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>一个map操作会触发一次 transform，那么transform做了什么工作呢？</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//DataStream line1020</span></div><div class="line"><span class="meta">@PublicEvolving</span></div><div class="line"><span class="keyword">public</span> &lt;R&gt; <span class="function">SingleOutputStreamOperator&lt;R&gt; <span class="title">transform</span><span class="params">(String operatorName, TypeInformation&lt;R&gt; outTypeInfo, OneInputStreamOperator&lt;T, R&gt; operator)</span> </span>&#123;</div><div class="line"></div><div class="line">   <span class="comment">// read the output type of the input Transform to coax out errors about MissingTypeInfo</span></div><div class="line">   transformation.getOutputType();</div><div class="line"></div><div class="line">   OneInputTransformation&lt;T, R&gt; resultTransform = <span class="keyword">new</span> OneInputTransformation&lt;&gt;(</div><div class="line">         <span class="keyword">this</span>.transformation,</div><div class="line">         operatorName,</div><div class="line">         operator,</div><div class="line">         outTypeInfo,</div><div class="line">         environment.getParallelism());</div><div class="line"></div><div class="line">   <span class="meta">@SuppressWarnings</span>(&#123; <span class="string">"unchecked"</span>, <span class="string">"rawtypes"</span> &#125;)</div><div class="line">   SingleOutputStreamOperator&lt;R&gt; returnStream = <span class="keyword">new</span> SingleOutputStreamOperator(environment, resultTransform);</div><div class="line"></div><div class="line">   getExecutionEnvironment().addOperator(resultTransform);</div><div class="line"></div><div class="line">   <span class="keyword">return</span> returnStream;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这一步生成了一个 <code>StreamTransformation</code>并以此作为成员变量封装成另一个 DataStream 返回，<code>StreamTransformation</code>是 flink关于数据流转换的核心抽象，只有需要 transform 的流才会生成新的DataStream 算子，后面会详细解释，注意上面有这一行<code>getExecutionEnvironment().addOperator(resultTransform)</code>flink会将transformation维护起来：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamExecutionEnvironment line 1237</span></div><div class="line"><span class="meta">@Internal</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addOperator</span><span class="params">(StreamTransformation&lt;?&gt; transformation)</span> </span>&#123;</div><div class="line">   Preconditions.checkNotNull(transformation, <span class="string">"transformation must not be null."</span>);</div><div class="line">   <span class="keyword">this</span>.transformations.add(transformation);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>所以，用户的一连串操作 map join等实际上在 DataStream 上做了转换，并且flink将这些 <code>StreamTransformation</code> 维护起来，一直到最后，用户执行 <code>env.execute()</code>这样一段逻辑，StreamGraph 的构建才算真正开始…</p>
<p>用户在执行<code>env.execute()</code>会触发这样一段逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamContextEnvironment line51   </span></div><div class="line"><span class="function"><span class="keyword">public</span> JobExecutionResult <span class="title">execute</span><span class="params">(String jobName)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">      Preconditions.checkNotNull(<span class="string">"Streaming Job name should not be null."</span>);</div><div class="line"></div><div class="line">      StreamGraph streamGraph = <span class="keyword">this</span>.getStreamGraph();</div><div class="line">      streamGraph.setJobName(jobName);</div><div class="line"></div><div class="line">      transformations.clear();</div><div class="line"></div><div class="line">      <span class="comment">// execute the programs</span></div><div class="line">      <span class="keyword">if</span> (ctx <span class="keyword">instanceof</span> DetachedEnvironment) &#123;</div><div class="line">         LOG.warn(<span class="string">"Job was executed in detached mode, the results will be available on completion."</span>);</div><div class="line">         ((DetachedEnvironment) ctx).setDetachedPlan(streamGraph);</div><div class="line">         <span class="keyword">return</span> DetachedEnvironment.DetachedJobExecutionResult.INSTANCE;</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">         <span class="keyword">return</span> ctx.getClient().runBlocking(streamGraph, ctx.getJars(), ctx.getClasspaths(), ctx.getUserCodeClassLoader(), ctx.getSavepointPath());</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这段代码做了两件事情：</p>
<ul>
<li>首先使用 <code>StreamGraphGenerator</code> 产生 StreamGraph</li>
<li>使用 Client 运行 stream graph</li>
</ul>
<p>那么<code>StreamGraphGenerator</code> 做了哪些操作呢？</p>
<p><code>StreamGraphGenerator</code>会依据添加算子时保存的 transformations 信息生成 job graph 中的节点，并创建节点连接，分流操作 如 union,select,split 不会添加边，只会创建虚拟节点或在上有节点添加 selector</p>
<p>这里会将 StreamTransformation 转换为 StreamNode，StreamNode 保存了算子的信息【会另外介绍】，如下图所示</p>
<p><img src="./transformation-to-node.png" width="535" height="300" alt="transformation-to-node.png" align="center"></p>
<p>到这里由 <code>StreamNode</code> 构成的 DAG 图 <code>StreamGraph</code>就生成了</p>
<p>不过 在提交给 client 的时候，flink 会做进一步的优化:</p>
<p> <code>StreamGraph</code> 将进一步转换为 <code>JobGraph</code>，这一步工作由 <code>StreamingJobGraphGenerator</code> 来完成，为什么要做这一步转换呢？主要因为有可以 chain 的算子，这里进一步将 StreamNode 转换为 JobVertex，主要工作是将可以 chain 的算子合并【这一步优化是默认打开的】，并设置资源，重试策略等，最终生成可以提交给 JobManager 的 JobGraph</p>
<h4 id="优化的逻辑计划-JobGraph-的生成"><a href="#优化的逻辑计划-JobGraph-的生成" class="headerlink" title="优化的逻辑计划 JobGraph 的生成"></a>优化的逻辑计划 JobGraph 的生成</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamingJobGraphGenerator line181</span></div><div class="line"><span class="function"><span class="keyword">private</span> List&lt;StreamEdge&gt; <span class="title">createChain</span><span class="params">(</span></span></div><div class="line">      Integer startNodeId,</div><div class="line">      Integer currentNodeId,</div><div class="line">      Map&lt;Integer, <span class="keyword">byte</span>[]&gt; hashes) &#123;</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (!builtVertices.contains(startNodeId)) &#123;</div><div class="line"></div><div class="line">      List&lt;StreamEdge&gt; transitiveOutEdges = <span class="keyword">new</span> ArrayList&lt;StreamEdge&gt;();</div><div class="line"></div><div class="line">      List&lt;StreamEdge&gt; chainableOutputs = <span class="keyword">new</span> ArrayList&lt;StreamEdge&gt;();</div><div class="line">      List&lt;StreamEdge&gt; nonChainableOutputs = <span class="keyword">new</span> ArrayList&lt;StreamEdge&gt;();</div><div class="line"></div><div class="line">      <span class="keyword">for</span> (StreamEdge outEdge : streamGraph.getStreamNode(currentNodeId).getOutEdges()) &#123;</div><div class="line">         <span class="keyword">if</span> (isChainable(outEdge)) &#123;</div><div class="line">            chainableOutputs.add(outEdge);</div><div class="line">         &#125; <span class="keyword">else</span> &#123;</div><div class="line">            nonChainableOutputs.add(outEdge);</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">for</span> (StreamEdge chainable : chainableOutputs) &#123;</div><div class="line">         transitiveOutEdges.addAll(createChain(startNodeId, chainable.getTargetId(), hashes));</div><div class="line">      &#125;</div><div class="line">     ...</div></pre></td></tr></table></figure>
<p>上面的方法是算子 chain 的核心操作，简要概括下：</p>
<ul>
<li>如果从此 start node 开始未生成过 JobVertex，则执行 chain逻辑，由于是递归操作，会先深度优先遍历，将源节点开始到第一个不可 chain 的 StreamNode 之间的算子做 chain 操作【先算叶子节点的 chain，依次往根节点计算】</li>
<li>line 207 遇到不可 chain 的边，开始深度遍历生成 JobVertex</li>
<li>line 216 将 StreamNode 的输入输出配置，包括序列化配置等设置到上面的 StreamingConfig 中，并在 vertexConfigs 中保存起来，如果是 新生成的 JobVertex，起对应的 StreamingConfig 会以 start node id 为 key 进行保存</li>
<li>transitiveOutEdges 保存的该节点下游所有的 non chain_able  edges，最终的方法会返回此数据结构</li>
<li>连接 start node 和所有的 transitiveOutEdges 【在输入 JobVertex 创建 IntermediateDataSet，partition类型为 pipeline，生成 JobEdge】</li>
<li>如果是新生成JobVertex，继续设置config，包括 chain start，所有物理输出，及直接逻辑输出、chained config等</li>
<li>如果不是新生成 JobVertex，直接chain configs</li>
</ul>
<p>这里总结下JobGraph的构建过程，见下图:</p>
<img src="/2016/12/03/Flink基本组件和逻辑计划/flink-job-graph-create.png" alt="flink-job-graph-create" title="flink-job-graph-create">
<p>大致过程总结如下：</p>
<ul>
<li>由<code>DataStream</code>上的操作生成<code>StreamTransformation</code>列表</li>
<li>从<code>StreamTransformation</code>的生成关系创建<code>StreamNode</code>和<code>StreamEdge</code></li>
<li>做算子chain，合并成 <code>JobVertex</code>，并生成 <code>JobEdge</code></li>
</ul>
<p>一个 JobVertex 代表一个逻辑计划的节点，就是 DAG 图上的顶点，有点类似于 Storm 的 bolt 或 spout，生成一个 JobVertex 的逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamingJobGenerator line258</span></div><div class="line"><span class="function"><span class="keyword">private</span> StreamConfig <span class="title">createJobVertex</span><span class="params">(</span></span></div><div class="line">      Integer streamNodeId,</div><div class="line">      Map&lt;Integer, <span class="keyword">byte</span>[]&gt; hashes) &#123;</div><div class="line"></div><div class="line">   JobVertex jobVertex;</div><div class="line">   ...</div><div class="line">   JobVertexID jobVertexId = <span class="keyword">new</span> JobVertexID(hash);</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (streamNode.getInputFormat() != <span class="keyword">null</span>) &#123;</div><div class="line">      jobVertex = <span class="keyword">new</span> InputFormatVertex(</div><div class="line">            chainedNames.get(streamNodeId),</div><div class="line">            jobVertexId);</div><div class="line">      TaskConfig taskConfig = <span class="keyword">new</span> TaskConfig(jobVertex.getConfiguration());</div><div class="line">      taskConfig.setStubWrapper(<span class="keyword">new</span> UserCodeObjectWrapper&lt;Object&gt;(streamNode.getInputFormat()));</div><div class="line">   &#125; <span class="keyword">else</span> &#123;</div><div class="line">      jobVertex = <span class="keyword">new</span> JobVertex(</div><div class="line">            chainedNames.get(streamNodeId),</div><div class="line">            jobVertexId);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   jobVertex.setInvokableClass(streamNode.getJobVertexClass());</div><div class="line"></div><div class="line">   ...</div><div class="line"></div><div class="line">   <span class="keyword">return</span> <span class="keyword">new</span> StreamConfig(jobVertex.getConfiguration());</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><em>这里有两段逻辑值得注意，第一是数据源节点的判断，第二是运行时执行类 InvokableClass 的设置</em></p>
<p><code>streamNode.getInputFormat()</code>是判断是否是数据源节点的逻辑，如果是数据源节点，这里会将用户代码【这里为 InputFormat.class 的子类】设置进 JobVertex 的配置中，并在 JobManager 执行提交作业命令的时候做初始化，会在 Flink 物理计划生成一节介绍。</p>
<p><code>jobVertex.setInvokableClass</code>是设置运行时的执行类，通过这个类再调用用户定义的 operator，是 flink task 中真正被执行的类，具体会在 flink-task-runtime 一节中详细介绍。</p>
<p>至此 JobGraph 生成，并扔给 JobManager 执行😝</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="https://danny0405.github.io/2016/12/03/Flink基本组件和逻辑计划/" data-id="ciwc266ws0002pxs6kbx9z6mz" class="article-share-link">分享到</a><div class="tags"><a href="/tags/Flink/">Flink</a></div><div id="disqus_thread"><script>var disqus_shortname = 'danny0405';
var disqus_identifier = '2016/12/03/Flink基本组件和逻辑计划/';
var disqus_title = 'Flink源码分析-基本组件和逻辑计划';
var disqus_url = 'https://danny0405.github.io/2016/12/03/Flink基本组件和逻辑计划/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//danny0405.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Streaming/">Streaming</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Flink/" style="font-size: 15px;">Flink</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/12/03/Flink基本组件和逻辑计划/">Flink源码分析-基本组件和逻辑计划</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> 最近评论</i></div><script type="text/javascript" src="//danny0405.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://hexo.io" title="Hexo" target="_blank">Hexo</a><ul></ul><a href="http://storm.apache.org" title="Apache Storm" target="_blank">Apache Storm</a><ul></ul><a href="https://flink.apache.org" title="Apache Flink" target="_blank">Apache Flink</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">玉兆的博客.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-88432446-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?1bde8b788c41c89cd3d082567500188c";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>