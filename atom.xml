<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>玉兆的博客</title>
  <subtitle>心如止水</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://danny0405.github.io/"/>
  <updated>2017-02-08T14:41:28.000Z</updated>
  <id>https://danny0405.github.io/</id>
  
  <author>
    <name>chenyuzhao</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>flink 算子的生命周期</title>
    <link href="https://danny0405.github.io/2017/02/08/flink%E7%AE%97%E5%AD%90%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"/>
    <id>https://danny0405.github.io/2017/02/08/flink算子的生命周期/</id>
    <published>2017-02-08T14:35:36.000Z</published>
    <updated>2017-02-08T14:41:28.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面已经介绍了 flink 的逻辑计划、物理计划等相关信息，本文将重点介绍 flink 的 operator 以及运行时的 task，后续会介绍 flink task 的调度算法</p>
<h2 id="算子"><a href="#算子" class="headerlink" title="算子"></a>算子</h2><h3 id="什么是一个算子"><a href="#什么是一个算子" class="headerlink" title="什么是一个算子"></a>什么是一个算子</h3><p>flink 中的一个 operator 代表一个最顶级的 api 接口，拿 streaming 来说就是，在 DataStream 上做诸如 map/reduce/keyBy 等操作均会生成一个算子</p>
<h3 id="算子的生成"><a href="#算子的生成" class="headerlink" title="算子的生成"></a>算子的生成</h3><p>先来看 operator 的继承关系:</p>
<p><img src="flink-operator-extend.png" alt="flink-operator-extend.png">对于 Streaming 来说所有的算子都继承自 StreamOperator，StreamOperator 中定义了一系列的生命周期方法，同时也定义了 snapshort 的接口，AbstractStreamOperator 定义了基本的设置和声明周期方法，AbstractUdfStreamOperator 定义了用户自定义函数的生命周期和快照策略，这些接口的调用时机会在下面一一阐述😄。</p>
<p>算子的生成触发于对 DataStream 的操作上，比如 map addSink等。</p>
<h3 id="算子-chain"><a href="#算子-chain" class="headerlink" title="算子 chain"></a>算子 chain</h3><p>在 <strong>flink 基本组件和逻辑计划生成一节</strong> 我们介绍了 JobGraph 的生成过程，其中 JobGraph 的生成最大的意义在于做了一些算子的 chain 优化，那么什么样的节点可以被 chain 呢？如下图：</p>
<p><img src="op-chian-chianable.png" alt="op-chian-chianable.png"></p>
<p>一些必须要经过 shuffle 的节点是 chain 或者 节点可达 的边界，非常类似于 Spark Streaming 中对于 Stage 的划分，上图中 keyBy 这样的 groupBy 操作就是划分是否可被 chain 的边界</p>
<p>在 StreamingJobGraphGenerator 的 createChain 方法中为每个 StreamNode 生成了一个 StreamConfig，并且对于可以生成 JobVertex 的节点[ <em>chain 的起始节点</em> ]设置了如下属性：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamingJobGraphGenerator line212</span></div><div class="line"><span class="keyword">if</span> (currentNodeId.equals(startNodeId)) &#123;</div><div class="line"></div><div class="line">   config.setChainStart();</div><div class="line">   config.setChainIndex(<span class="number">0</span>);</div><div class="line">   config.setOutEdgesInOrder(transitiveOutEdges);</div><div class="line">   config.setOutEdges(streamGraph.getStreamNode(currentNodeId).getOutEdges());</div><div class="line"></div><div class="line">   <span class="keyword">for</span> (StreamEdge edge : transitiveOutEdges) &#123;</div><div class="line">      connect(startNodeId, edge);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   config.setTransitiveChainedTaskConfigs(chainedConfigs.get(startNodeId));</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面的逻辑概括如下：</p>
<ul>
<li>标志本节点为 chain 的起始位置</li>
<li>设置 chain 的索引</li>
<li>设置可达输出边，就是与下游 JobVertex 直接连接的 StreamEdge</li>
<li>设置自身的直接输出边 StreamEdge</li>
<li>将本 JobVertex 与下游的 JobVertex 连接起来</li>
<li>将被 chained 的可达的下游 StreamNode 的配置一同设置进本 JobVertex 的配置中，后面 task 运行时会用到</li>
</ul>
<p>连接的逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamingJobGraphGenerator line357</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">(Integer headOfChain, StreamEdge edge)</span> </span>&#123;</div><div class="line"></div><div class="line">   physicalEdgesInOrder.add(edge);</div><div class="line"></div><div class="line">   Integer downStreamvertexID = edge.getTargetId();</div><div class="line"></div><div class="line">   JobVertex headVertex = jobVertices.get(headOfChain);</div><div class="line">   JobVertex downStreamVertex = jobVertices.get(downStreamvertexID);</div><div class="line"></div><div class="line">   StreamConfig downStreamConfig = <span class="keyword">new</span> StreamConfig(downStreamVertex.getConfiguration());</div><div class="line"></div><div class="line">   downStreamConfig.setNumberOfInputs(downStreamConfig.getNumberOfInputs() + <span class="number">1</span>);</div><div class="line"></div><div class="line">   StreamPartitioner&lt;?&gt; partitioner = edge.getPartitioner();</div><div class="line">   <span class="keyword">if</span> (partitioner <span class="keyword">instanceof</span> ForwardPartitioner) &#123;</div><div class="line">      downStreamVertex.connectNewDataSetAsInput(</div><div class="line">         headVertex,</div><div class="line">         DistributionPattern.POINTWISE,</div><div class="line">         ResultPartitionType.PIPELINED,</div><div class="line">         <span class="keyword">true</span>);</div><div class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (partitioner <span class="keyword">instanceof</span> RescalePartitioner)&#123;</div><div class="line">      downStreamVertex.connectNewDataSetAsInput(</div><div class="line">         headVertex,</div><div class="line">         DistributionPattern.POINTWISE,</div><div class="line">         ResultPartitionType.PIPELINED,</div><div class="line">         <span class="keyword">true</span>);</div><div class="line">   &#125; <span class="keyword">else</span> &#123;</div><div class="line">      downStreamVertex.connectNewDataSetAsInput(</div><div class="line">            headVertex,</div><div class="line">            DistributionPattern.ALL_TO_ALL,</div><div class="line">            ResultPartitionType.PIPELINED,</div><div class="line">            <span class="keyword">true</span>);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</div><div class="line">      LOG.debug(<span class="string">"CONNECTED: &#123;&#125; - &#123;&#125; -&gt; &#123;&#125;"</span>, partitioner.getClass().getSimpleName(),</div><div class="line">            headOfChain, downStreamvertexID);</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>概括下逻辑：</p>
<ul>
<li>获取要连接的两个 JobVertex 对象</li>
<li>设置下游 JobVertex 的输入 partition 算法，如果是 forward 或 rescale 的话为 POINTWISE，否则为全连接，也就是 shuffle，POINTWISE 的连接算法在 <strong>flink 物理计划生成</strong> 一节已经介绍，这里不再赘述</li>
</ul>
<p><em>以上只是客户端生成逻辑计划时的算子 chain，在运行时算子的的 chain 被封装成了一个单独的对象 OperatorChain，里面在原有的基础上将 operators 的操作封装起来并且确定了下游的的输出入口</em></p>
<p>来看 OperatorChain 的核心实现</p>
<p>首先总结下构造器的功能:</p>
<ul>
<li>获取可达的 chain 的 StreamNode 配置</li>
<li>为直接可达的输出 StreamEdge 分别创建一个 Output，这里为 RecordWriterOutput</li>
<li>创建chain的入口</li>
<li>如果创建有任何失败，释放掉 RecordWriterOutput 占用的资源，主要是内存 buffer，后面章节会介绍</li>
</ul>
<p>这里的关键是算子 chain 的创建过程，见下图创建过程：</p>
<p><img src="op-chain-internal.png" alt="op-chain-internal.png"></p>
<p>上图中 S 节点的下游 A/B/C 是可以与 S Chain 在一起的，D/E 是必须经过网络传输的节点，一个 OperatorChain 封装了图中的节点 S/A/B/C，也就是说上图可以被看做如下所示：</p>
<p><img src="operator-chain-simple.png" alt="operator-chain-simple.png"></p>
<p>OperatorChain 中有两个关键的方法：<code>createOutputCollector</code> 和 <code>createChainedOperator</code>，前者负责获取一个 StreamNode 的输出Output，后者负责创建 StreamNode 对应的 chain 算子，两者相互调用形成递归，如上面的创建过程图，具体的流程如下：</p>
<ul>
<li>创建 S 的所有网络输出 RecordWriterOutput，这里会为 D 和 E 分别创建一个</li>
<li>由于从 A 开始对于 S 是可被 chain 的，会递归创建从 C 开始</li>
<li>先获取 C 的输出，这里为对应 D 的 RecordWriterOutput</li>
<li>拿到 C 对应的 StreamOperator 并将 运行时的 StreamTask 和 Output 设置进去</li>
<li>将 StreamOperator 封装成 ChainingOutput 并作为 Output 传给 B</li>
<li>B 将重复 C 的过程，直到 S/A/B/C 全部被创建</li>
</ul>
<p><em>那么 S 发射一条消息后的处理流程是如何呢？</em></p>
<p>S 在调用 <code>processElement</code> 方法时会调用 <code>output.collect</code>，这里的 output 为 A 对应的 ChainingOutput，ChainingOutput 的 collect 调用了对应的算子 <code>StreamOperator A</code> 的 <code>processElement</code> 方法，这里又会调用 B 的 ChainingOutput 的 collect 方法，以此类推。这样便实现了可 chain 算子的本地处理，最终经由网络输出 RecordWriterOutput 发送到下游节点</p>
<h3 id="算子的运行"><a href="#算子的运行" class="headerlink" title="算子的运行"></a>算子的运行</h3><p>flink 算子的运行牵涉到两个关键类 <code>Task.java</code> 和 <code>StreamTask.java</code>，Task 是直接受 TaskManager 管理和调度的，而 Task 又会调用 StreamTask，StreamTask 中封装了算子的处理逻辑</p>
<p><strong>我们先来看 StreamTask</strong></p>
<p>StreamTask 的 JavaDoc 上描述了其生命周期:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">*  -- restoreState() -&gt; restores state of all operators in the chain</div><div class="line">*  </div><div class="line">*  -- invoke()</div><div class="line">*        |</div><div class="line">*        +----&gt; <span class="function">Create basic <span class="title">utils</span> <span class="params">(config, etc)</span> and load the chain of operators</span></div><div class="line">*        +----&gt; operators.<span class="title">setup</span><span class="params">()</span></div><div class="line">*        +----&gt; task specific <span class="title">init</span><span class="params">()</span></div><div class="line">*        +----&gt; open-<span class="title">operators</span><span class="params">()</span></div><div class="line">*        +----&gt; <span class="title">run</span><span class="params">()</span></div><div class="line">*        +----&gt; close-<span class="title">operators</span><span class="params">()</span></div><div class="line">*        +----&gt; dispose-<span class="title">operators</span><span class="params">()</span></div><div class="line">*        +----&gt; common cleanup</div><div class="line">*        +----&gt; task specific <span class="title">cleanup</span><span class="params">()</span></div></pre></td></tr></table></figure>
<p>StreamTask 运行之初会尝试恢复算子的 State 快照，然后由 Task 调用其 invoke 方法</p>
<p>下面重点分析一下其 invoke 方法的实现</p>
<ul>
<li>获取 headOperator，这里的 headOperator 在 StreamingJobGraphGenerator line 210 <code>setVertexConfig(currentNodeId, config, chainableOutputs, nonChainableOutputs);</code>设置，对应上面算子 chain 中的 S 节点</li>
<li>创建 operatorChain 并设置为 headOperator 的 Output</li>
<li><code>init()</code></li>
<li><code>restoreState</code></li>
<li>执行 operatorChain 中所有 operator 的 open 方法</li>
<li><code>run()</code></li>
<li>执行 operatorChain 中所有 operator 的 close 方法</li>
<li>执行资源回收及 <code>cleanup()</code>，最主要的目的是回收内存 buffer</li>
</ul>
<p>StreamTask 中还有关于 Checkpoint 和 StateBackup 的核心逻辑，这里先不介绍，会另开一篇😄</p>
<p>我们来看 StreamTask 的实现类之一 OneInputStreamTask ，便可以知道 <code>init()</code> 和 <code>run()</code> 分别都做了什么：</p>
<p><strong>init方法</strong>：</p>
<ul>
<li>获取算子对应的输入序列化器 TypeSerializer</li>
<li>获取输入数据 InputGate[]，InputGate 是 flink 网络传输的核心抽象之一，其在内部封装了消息的接收和内存的管理，后面介绍 flink 网络栈的时候会详细介绍，这里只要了解从 InputGate 可以拿到上游传送过来的数据就可以了</li>
<li>初始化 StreamInputProcessor</li>
<li>设置一些 metrics 及 累加器</li>
</ul>
<p>StreamInputProcessor 是 StreamTask 内部用来处理 Record 的组件，里面封装了外部 IO 逻辑【<em>内存不够时将 buffer 吐到磁盘上</em>】以及 时间对齐逻辑【<em>Watermark</em>】，这两个将会合并一节在下一章介绍^_^</p>
<p><strong>run方法</strong>:</p>
<ul>
<li>从 StreamInputProcessor 中处理一条记录</li>
<li>check 是否有异常</li>
</ul>
<p><strong>真正的运行时类 Task</strong></p>
<p> <em>这里我们会详细的介绍下 Task 的核心逻辑</em></p>
<p>Task 代表一个 TaskManager 中所起的并行 子任务，执行封装的 flink 算子并运行，提供以下服务：消费输入data、生产 IntermediateResultPartition [ <em>flink关于中间结果的抽象</em> ]、与 JobManager 交互</p>
<p>JobManager 分发 Task 时最初是抽象成了一个描述类 TaskDeploymentDescriptor，TaskManager 在抽到对应的 RPC 请求后会将 Task 初始化后将 线程 拉起，TaskDeploymentDescriptor 是提供 task 信息的核心抽象：</p>
<ul>
<li>ResultPartitions：task 输出的 partition 数[ <em>通常和 JobVertex 的下游节点数对应</em>  ]</li>
<li>InputGates：task 的输入中间结果 partition</li>
<li>operator-state：算子的状态句柄，由 TaskManager 上报给 JobManager，并统一维护</li>
<li>jar-files</li>
<li>class-paths</li>
</ul>
<p>构造器的一些组件我们会在介绍 TaskManager 的时候再详述</p>
<p>其核心的运行方法 run()逻辑总结如下：</p>
<p>line408: run</p>
<ul>
<li>核心的运行逻辑</li>
<li>line429: 遇到错误后通知 TaskManager</li>
<li>line469: 从 NetworkEnvironment 中申请 BufferPool，包括 InputGate 的接收 pool 以及 task 的每个 ResultPartition 的输出 pool，申请的资源数[ <em>num of Buffer</em> ] 由 input channels 和 ResultSubPartition 数决定</li>
</ul>
<p>关于网络管理[ 输入和输出 ] NetworkEnvironment，内存管理 MemoryManager 会分别开章节介绍</p>
<p>那么 StreamTask 是如何在 Task 中被实例化，又是如何被调用的呢？</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//line 418</span></div><div class="line">invokable = loadAndInstantiateInvokable(userCodeClassLoader, nameOfInvokableClass);</div><div class="line"><span class="comment">//一系列初始化操作 ...</span></div><div class="line"><span class="comment">//line 584</span></div><div class="line">invokable.invoke();</div></pre></td></tr></table></figure>
<p>上面的 invokable 就是 StreamTask，StreamTask  的继承关系:</p>
<p><img src="stream-task-extend.png" alt="stream-task-extend.png"></p>
<p>那么具体是什么时候被 set 进去作为属性的呢？</p>
<p>在 StreamNode 生成的时候有这样一段逻辑:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> &lt;IN, OUT&gt; <span class="function"><span class="keyword">void</span> <span class="title">addOperator</span><span class="params">(</span></span></div><div class="line">      Integer vertexID,</div><div class="line">      String slotSharingGroup,</div><div class="line">      StreamOperator&lt;OUT&gt; operatorObject,</div><div class="line">      TypeInformation&lt;IN&gt; inTypeInfo,</div><div class="line">      TypeInformation&lt;OUT&gt; outTypeInfo,</div><div class="line">      String operatorName) &#123;</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (operatorObject <span class="keyword">instanceof</span> StoppableStreamSource) &#123;</div><div class="line">      addNode(vertexID, slotSharingGroup, StoppableSourceStreamTask.class, operatorObject, operatorName);</div><div class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (operatorObject <span class="keyword">instanceof</span> StreamSource) &#123;</div><div class="line">      addNode(vertexID, slotSharingGroup, SourceStreamTask.class, operatorObject, operatorName);</div><div class="line">   &#125; <span class="keyword">else</span> &#123;</div><div class="line">      addNode(vertexID, slotSharingGroup, OneInputStreamTask.class, operatorObject, operatorName);</div><div class="line">   &#125;</div></pre></td></tr></table></figure>
<p>将 OneInputStreamTask 等 StreamTask 设置到 StreamNode 的节点属性中，同时在 JobVertex 的节点构造时也会做一次初始化:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">jobVertex.setInvokableClass(streamNode.getJobVertexClass());</div></pre></td></tr></table></figure>
<p>在 TaskDeploymentDescriptor 实例化的时候会获取 jobVertex 中的属性，见<code>ExecutionVertex line673</code></p>
<h4 id="算子初始化"><a href="#算子初始化" class="headerlink" title="算子初始化"></a>算子初始化</h4><p>那么算子是什么时候被初始化的呢？这就需要梳理下 StreamTask 的 <code>init()</code> 方法的处理时机，上面已经分析过 <code>init()</code> 方法会在 StreamTask 的 <code>invoke()</code> 方法中被调用，那么 <code>invoke()</code> 方法又是何时被调用的呢？这就涉及到另外一个重要的类 Task.java，Task 才是运行时真正直接被 TaskManager 实例化和调用的类，上面已经分析过 Task 的 run 方法，是 TaskManager 收到 rpc 命令后起起来的 具体的细节会另起一章 flink 任务分发</p>
<h4 id="算子销毁"><a href="#算子销毁" class="headerlink" title="算子销毁"></a>算子销毁</h4><p>StreamTask 下执行完 invoke 方法之后[<em>意味着流程正常结束或者有异常打断</em>]，会执行下面这段逻辑:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Execute the operator-specific &#123;<span class="doctag">@link</span> StreamOperator#dispose()&#125; method in each</div><div class="line"> * of the operators in the chain of this &#123;<span class="doctag">@link</span> StreamTask&#125;. &lt;/b&gt; Disposing happens</div><div class="line"> * from &lt;b&gt;tail to head&lt;/b&gt; operator in the chain.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">tryDisposeAllOperators</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">   <span class="keyword">for</span> (StreamOperator&lt;?&gt; operator : operatorChain.getAllOperators()) &#123;</div><div class="line">      <span class="keyword">if</span> (operator != <span class="keyword">null</span>) &#123;</div><div class="line">         operator.dispose();</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>所以，算子中有任何 hook 函数或者必须执行的销毁工作可以写在 dispose 方法里，这段逻辑是 flink 保证一定可以执行到的</p>
]]></content>
    
    <summary type="html">
    
      前面已经介绍了 flink 的逻辑计划、物理计划等相关信息，本文将重点介绍 flink 的 operator 以及运行时的 task，后续会介绍 flink task 的调度算法
    
    </summary>
    
      <category term="Streaming" scheme="https://danny0405.github.io/categories/Streaming/"/>
    
    
      <category term="flink" scheme="https://danny0405.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>jobmanager 基本组件</title>
    <link href="https://danny0405.github.io/2017/02/08/jobmanager%E5%9F%BA%E6%9C%AC%E7%BB%84%E4%BB%B6/"/>
    <id>https://danny0405.github.io/2017/02/08/jobmanager基本组件/</id>
    <published>2017-02-08T14:22:33.000Z</published>
    <updated>2017-02-08T14:39:39.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>JobManager 是 flink 集群的中控节点，类似于 Apache Storm 的 Nimbus 以及 Apache Spark 的 Driver 的角色，它负责作业的调度、jar 包管理、checkpoint 的协调和发起等，为了后续章节的开展，本文将介绍 flink JobManager 中所部署的一些服务。</p>
<h2 id="BolbServer"><a href="#BolbServer" class="headerlink" title="BolbServer"></a>BolbServer</h2><p>flink 用来管理二进制大文件的服务，flink JobManager 中启动的 BLOB Server 负责监听请求并派发线程去处理。更进一步，它将负责创建对应的目录结构去存储这些 BLOBs 或者只是临时性地缓存。背后支持的文件系统：本底磁盘</p>
<p>来看它的构造器：</p>
<ul>
<li>第一步获取 RecoveryMode，一共两种 STANDALONE 和 ZOOKEEPER，后者是有 JobManager leader 选举的高可用模式</li>
<li>获取文件系统存储的根目录，可配置，默认是从系统环境变量 <code>System.getProperty(&quot;java.io.tmpdir&quot;)</code> 中获取，其实就是本次磁盘存储</li>
<li>初始化 <em>恢复存储</em> 模块 BolbStore，STANDALONE 模式下为 VoidBlobStore，VoidBlobStore 是一个空实现；不会有任何持久化操作；ZOOKEEPER 模式下为 FileSystemBlobStore，FileSystemBlobStore 内部封装了磁盘文件的管理，包括添加、删除、拷贝等，BlogStore 会备份 BlobServer 的本地存储，主要用于恢复模式下的作业磁盘状态恢复用</li>
<li>启动 ServerSocket</li>
<li>启动 BlobServer 服务线程</li>
</ul>
<h3 id="BlogServer-和-BlobStore"><a href="#BlogServer-和-BlobStore" class="headerlink" title="BlogServer 和 BlobStore"></a>BlogServer 和 BlobStore</h3><p>BlobStore 是 BlobServer 的组件之一，BolbStore 主要负责 BlobServer 本地存储的恢复【JobManager 重启】，这里只介绍 FileSystemBlobStore，FileSystemBlobStore 依据配置的不同支持两种文件系统存储：HDFS 和 本地文件系统</p>
<p>BlobServer 和  FileSystemBlobStore 的存储目录结构如下图所示：</p>
<p><img src="blob-server-store-dirctory-tree.png" alt="blob-server-store-dirctory-tree.png"></p>
<p><em>下面以一次客户端连接请求的发起介绍两者的协同</em></p>
<p>来看 BolbServer 的核心 <code>run</code> 方法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//BlobServer line230</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">   <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">while</span> (!<span class="keyword">this</span>.shutdownRequested.get()) &#123;</div><div class="line">         BlobServerConnection conn = <span class="keyword">new</span> BlobServerConnection(serverSocket.accept(), <span class="keyword">this</span>);</div><div class="line">         <span class="keyword">try</span> &#123;</div><div class="line">            <span class="keyword">synchronized</span> (activeConnections) &#123;</div><div class="line">               <span class="keyword">while</span> (activeConnections.size() &gt;= maxConnections) &#123;</div><div class="line">                  activeConnections.wait(<span class="number">2000</span>);</div><div class="line">               &#125;</div><div class="line">               activeConnections.add(conn);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            conn.start();</div><div class="line">            conn = <span class="keyword">null</span>;</div><div class="line">         &#125;</div><div class="line">         <span class="keyword">finally</span> &#123;</div><div class="line">            <span class="keyword">if</span> (conn != <span class="keyword">null</span>) &#123;</div><div class="line">               conn.close();</div><div class="line">               <span class="keyword">synchronized</span> (activeConnections) &#123;</div><div class="line">                  activeConnections.remove(conn);</div><div class="line">               &#125;</div><div class="line">            &#125;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">   &#125;</div></pre></td></tr></table></figure>
<p>简要概括下逻辑：</p>
<ul>
<li>当服务端收到一次存储的 request 时，会首先封装成对象 BlobServerConnection，并执行其 <code>start()</code> 方法</li>
<li>BlobServerConnection 本身也是一个 Thread，封装了具体的存储逻辑</li>
<li>会接收 3 种客户端请求：PUT/GET/DELETE，具体见：</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//BlobServerConnection line111</span></div><div class="line"><span class="keyword">switch</span> (operation) &#123;</div><div class="line"><span class="keyword">case</span> PUT_OPERATION:</div><div class="line">   put(inputStream, outputStream, buffer);</div><div class="line">   <span class="keyword">break</span>;</div><div class="line"><span class="keyword">case</span> GET_OPERATION:</div><div class="line">   get(inputStream, outputStream, buffer);</div><div class="line">   <span class="keyword">break</span>;</div><div class="line"><span class="keyword">case</span> DELETE_OPERATION:</div><div class="line">   delete(inputStream, outputStream, buffer);</div><div class="line">   <span class="keyword">break</span>;</div><div class="line"><span class="keyword">default</span>:</div><div class="line">   <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unknown operation "</span> + operation);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><em>这里重点介绍下 PUT 操作</em></p>
<ul>
<li>获取本次存储操作是否带 JobID</li>
<li>在 BlobServer 的本地 incoming 文件夹中生成临时文件：temp-[auto increment integer]</li>
<li>读取将要存储的字节长度</li>
<li>读取该长度字节存储到临时文件 temp-[auto increment integer]</li>
<li>如果带 JobID，会将临时文件移动到 JobID 对应的存储目录，并将该存储文件在 BlobStore 的对应 JobID恢复目录中备份，写 OK 消息到 Socket Client 端，最终生成的路径和文件： job-id/blob_[base64 encode key]</li>
<li>如果不带 JobID，则依据传递的消息字节数组生成一个 key：BlogKey，并存储在 cache 文件夹下，同时在 BlobStore 的 cache 文件夹下做备份，将 OK 消息和 BlobKey 写回 Socket Client，最终生成的路径和文件：cache/blob_[unique hex string]</li>
</ul>
<h3 id="BlobServer-交互协议"><a href="#BlobServer-交互协议" class="headerlink" title="BlobServer 交互协议"></a>BlobServer 交互协议</h3><p>与 BlobServer 通信的消息协议包括四段：操作类型【PUT/GET/DELETE】、存储类型【是否带 JobID】、内容长度、内容，如下图所示：</p>
<p><img src="blob-server-contact.png" alt="blob-server-contact.png"></p>
<p><em>到这里 BlobServer 就介绍完了</em></p>
<h2 id="InstanceManager"><a href="#InstanceManager" class="headerlink" title="InstanceManager"></a>InstanceManager</h2><p>flink 用来追踪当前存活的 TaskManager 的管理组件，实现比较简单，这里只简单罗列下其功能：</p>
<ul>
<li>book 下载 JobManager 中注册的所有 TaskManager</li>
<li>负责更新从 TaskManager 中上报的心跳及 metrics 信息</li>
<li>通知 InstanceListener TaskManager 的增加与死亡</li>
</ul>
<h2 id="BlobLibraryCacheManager"><a href="#BlobLibraryCacheManager" class="headerlink" title="BlobLibraryCacheManager"></a>BlobLibraryCacheManager</h2><p>flink job 的 jar 包存储服务，使用上面的 BlobServer 完成，一个 JVM 里只会存在一个 BlobLibraryCacheManager，BlobLibraryCacheManager 负责管理 BlobService【这里为BlobServer】 中存储的 jars，并存储运行时 task 对 BlobService 中 jars 的引用计数，会清理不被使用任何 task 使用的 jars。</p>
<p><em>BlobCache 负责 jars 的下载，介绍 TaskManager 的时候会详细介绍</em></p>
<p>BlobLibraryCacheManager 与 BlobService 交互，而 BlobService 负责具体的文件管理，其具体实现有两个：BlobServer 和 BlobCache，具体见下图：</p>
<p><img src="blob-service-extends-arch.png" alt="blob-service-extends-arch.png"></p>
<p>BlobServer 前面已经介绍过了，那么 BlobCache 的功能是什么呢？</p>
<p>来看 BlobCache 的构造器：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//BlobCache line60</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">BlobCache</span><span class="params">(InetSocketAddress serverAddress, Configuration configuration)</span> </span>&#123;</div><div class="line">   <span class="keyword">if</span> (serverAddress == <span class="keyword">null</span> || configuration == <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.serverAddress = serverAddress;</div><div class="line"></div><div class="line">   <span class="comment">// configure and create the storage directory</span></div><div class="line">   String storageDirectory = configuration.getString(ConfigConstants.BLOB_STORAGE_DIRECTORY_KEY, <span class="keyword">null</span>);</div><div class="line">   <span class="keyword">this</span>.storageDir = BlobUtils.initStorageDirectory(storageDirectory);</div><div class="line">   LOG.info(<span class="string">"Created BLOB cache storage directory "</span> + storageDir);</div></pre></td></tr></table></figure>
<p>这里传入的 serverAddress 其实是 BlobServer 的服务端口，在 TaskManager 中可以看到：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// start a blob service, if a blob server is specified TaskManager line940</span></div><div class="line"><span class="keyword">if</span> (blobPort &gt; <span class="number">0</span>) &#123;</div><div class="line">  val jmHost = jobManager.path.address.host.getOrElse(<span class="string">"localhost"</span>)</div><div class="line">  val address = <span class="keyword">new</span> InetSocketAddress(jmHost, blobPort)</div><div class="line"></div><div class="line">  log.info(s<span class="string">"Determined BLOB server address to be $address. Starting BLOB cache."</span>)</div><div class="line"></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    val blobcache = <span class="keyword">new</span> BlobCache(address, config.configuration)</div><div class="line">    blobService = Option(blobcache)</div><div class="line">    libraryCacheManager = Some(<span class="keyword">new</span> BlobLibraryCacheManager(blobcache, config.cleanupInterval))</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>来看 BlobCache 的核心服务方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//BlobCache line97</span></div><div class="line"><span class="function"><span class="keyword">public</span> URL <span class="title">getURL</span><span class="params">(<span class="keyword">final</span> BlobKey requiredBlob)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">   <span class="keyword">if</span> (requiredBlob == <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"BLOB key cannot be null."</span>);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">final</span> File localJarFile = BlobUtils.getStorageLocation(storageDir, requiredBlob);</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (!localJarFile.exists()) &#123;</div><div class="line"></div><div class="line">      <span class="keyword">final</span> <span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[BlobServerProtocol.BUFFER_SIZE];</div><div class="line"></div><div class="line">      <span class="comment">// loop over retries</span></div><div class="line">      <span class="keyword">int</span> attempt = <span class="number">0</span>;</div><div class="line">      <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line"></div><div class="line">         <span class="keyword">if</span> (attempt == <span class="number">0</span>) &#123;</div><div class="line">            LOG.info(<span class="string">"Downloading &#123;&#125; from &#123;&#125;"</span>, requiredBlob, serverAddress);</div><div class="line">         &#125; <span class="keyword">else</span> &#123;</div><div class="line">            LOG.info(<span class="string">"Downloading &#123;&#125; from &#123;&#125; (retry &#123;&#125;)"</span>, requiredBlob, serverAddress, attempt);</div><div class="line">         &#125;</div><div class="line"></div><div class="line">         <span class="keyword">try</span> &#123;</div><div class="line">            BlobClient bc = <span class="keyword">null</span>;</div><div class="line">            InputStream is = <span class="keyword">null</span>;</div><div class="line">            OutputStream os = <span class="keyword">null</span>;</div><div class="line"></div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">               bc = <span class="keyword">new</span> BlobClient(serverAddress);</div><div class="line">               is = bc.get(requiredBlob);</div><div class="line">               os = <span class="keyword">new</span> FileOutputStream(localJarFile);</div><div class="line"></div><div class="line">               <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">                  <span class="keyword">final</span> <span class="keyword">int</span> read = is.read(buf);</div><div class="line">                  <span class="keyword">if</span> (read &lt; <span class="number">0</span>) &#123;</div><div class="line">                     <span class="keyword">break</span>;</div><div class="line">                  &#125;</div><div class="line">                  os.write(buf, <span class="number">0</span>, read);</div><div class="line">               &#125;</div><div class="line"></div><div class="line">               <span class="comment">// we do explicitly not use a finally block, because we want the closing</span></div><div class="line">               <span class="comment">// in the regular case to throw exceptions and cause the writing to fail.</span></div><div class="line">               <span class="comment">// But, the closing on exception should not throw further exceptions and</span></div><div class="line">               <span class="comment">// let us keep the root exception</span></div><div class="line">               os.close();</div><div class="line">               os = <span class="keyword">null</span>;</div><div class="line">               is.close();</div><div class="line">               is = <span class="keyword">null</span>;</div><div class="line">               bc.close();</div><div class="line">               bc = <span class="keyword">null</span>;</div><div class="line"></div><div class="line">               <span class="comment">// success, we finished</span></div><div class="line">               <span class="keyword">break</span>;</div></pre></td></tr></table></figure>
<p>简要概括下其逻辑：</p>
<ul>
<li>先从本地磁盘中获取，如果存在，直接返回</li>
<li>如果没有，生成 BlobClient 与 BlobServer 交互，并拉取文件到本地缓存，后返回本地缓存的文件句柄</li>
</ul>
<p>从这里我们可以看到 BlobCache 是 TaskManager 操作本地文件的工具，它负责从 JobManager 中的 BlobServer 同步所需的文件【jar包等】，而 BlobServer 和 BlobCache 的文件管理的入口，统一由对应 JVM 中的 BlobLibraryCacheManager 来控制【没有任务使用的 jar 定期清除等】。</p>
<p>task 拉取 jar包文件的过程如下：</p>
<p><img src="blob-server-cache-store.png" alt="blob-server-cache-store.png"></p>
<h2 id="ZooKeeperCompletedCheckpointStore"><a href="#ZooKeeperCompletedCheckpointStore" class="headerlink" title="ZooKeeperCompletedCheckpointStore"></a>ZooKeeperCompletedCheckpointStore</h2><p>flink 做 checkpoint 【有关 checkpoint 会另起一节介绍】存储的组件，负责存储已完成的 Checkpoint ，实现了接口 CompletedCheckpointStore，StandaloneCompletedCheckpointStore 和 ZooKeeperCompletedCheckpointStore 都实现了 CompletedCheckpointStore 接口，前者只在内存里存储 checkpoint，这里只介绍 ZooKeeperCompletedCheckpointStore 的实现。</p>
<p>ZooKeeperCompletedCheckpointStore 存储 checkpoint 的基本思路：</p>
<ul>
<li>先在本地磁盘持久化指定数量的 checkpoint</li>
<li>将文件句柄更新到 ZK 的特定节点下</li>
<li>滑动更新 zk 的节点存储</li>
<li>在恢复的时候只取最近一次的更新值</li>
</ul>
<p>先来看下  ZooKeeperCompletedCheckpointStore 用来和 ZK 存储交互的组件：ZooKeeperStateHandleStore，来看它的核心添加 state 的方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ZooKeeperStateHandleStore line117</span></div><div class="line"><span class="function"><span class="keyword">public</span> StateHandle&lt;T&gt; <span class="title">add</span><span class="params">(</span></span></div><div class="line">      String pathInZooKeeper,</div><div class="line">      T state,</div><div class="line">      CreateMode createMode) <span class="keyword">throws</span> Exception &#123;</div><div class="line">   checkNotNull(pathInZooKeeper, <span class="string">"Path in ZooKeeper"</span>);</div><div class="line">   checkNotNull(state, <span class="string">"State"</span>);</div><div class="line"></div><div class="line">   StateHandle&lt;T&gt; stateHandle = storage.store(state);</div><div class="line"></div><div class="line">   <span class="keyword">boolean</span> success = <span class="keyword">false</span>;</div><div class="line"></div><div class="line">   <span class="keyword">try</span> &#123;</div><div class="line">      <span class="comment">// Serialize the state handle. This writes the state to the backend.</span></div><div class="line">      <span class="keyword">byte</span>[] serializedStateHandle = InstantiationUtil.serializeObject(stateHandle);</div><div class="line"></div><div class="line">      <span class="comment">// Write state handle (not the actual state) to ZooKeeper. This is expected to be</span></div><div class="line">      <span class="comment">// smaller than the state itself. This level of indirection makes sure that data in</span></div><div class="line">      <span class="comment">// ZooKeeper is small, because ZooKeeper is designed for data in the KB range, but</span></div><div class="line">      <span class="comment">// the state can be larger.</span></div><div class="line">      client.create().withMode(createMode).forPath(pathInZooKeeper, serializedStateHandle);</div><div class="line"></div><div class="line">      success = <span class="keyword">true</span>;</div><div class="line"></div><div class="line">      <span class="keyword">return</span> stateHandle;</div><div class="line">   &#125;</div><div class="line">   <span class="keyword">finally</span> &#123;</div><div class="line">      <span class="keyword">if</span> (!success) &#123;</div><div class="line">         <span class="comment">// Cleanup the state handle if it was not written to ZooKeeper.</span></div><div class="line">         <span class="keyword">if</span> (stateHandle != <span class="keyword">null</span>) &#123;</div><div class="line">            stateHandle.discardState();</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简要概括其逻辑：</p>
<ul>
<li>使用 StateStorageHelper 存储 state，ZK 模式下为 FileSystemStateStorageHelper，方式为直接存储到本地磁盘</li>
<li>将 state 的句柄对象 StateHandle 序列化并持久化到 ZK 的节点</li>
</ul>
<p>其在 zk 上的存储路径如下图所示：</p>
<p><img src="zk-state-handle-storage.png" width="300" height="300" alt="zk-state-handle-storage.png" align="center"></p>
<p>现在来看 ZooKeeperCompletedCheckpointStore 的核心功能：添加 checkpoint 和 从 checkpoint 做 recovery</p>
<h3 id="添加-checkpoint"><a href="#添加-checkpoint" class="headerlink" title="添加 checkpoint"></a>添加 checkpoint</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ZooKeeperCompletedCheckpointStore line190</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addCheckpoint</span><span class="params">(CompletedCheckpoint checkpoint)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">   checkNotNull(checkpoint, <span class="string">"Checkpoint"</span>);</div><div class="line"></div><div class="line">   <span class="comment">// First add the new one. If it fails, we don't want to loose existing data.</span></div><div class="line">   String path = String.format(<span class="string">"/%s"</span>, checkpoint.getCheckpointID());</div><div class="line"></div><div class="line">   <span class="keyword">final</span> StateHandle&lt;CompletedCheckpoint&gt; stateHandle = checkpointsInZooKeeper.add(path, checkpoint);</div><div class="line"></div><div class="line">   checkpointStateHandles.addLast(<span class="keyword">new</span> Tuple2&lt;&gt;(stateHandle, path));</div><div class="line"></div><div class="line">   <span class="comment">// Everything worked, let's remove a previous checkpoint if necessary.</span></div><div class="line">   <span class="keyword">if</span> (checkpointStateHandles.size() &gt; maxNumberOfCheckpointsToRetain) &#123;</div><div class="line">      removeFromZooKeeperAndDiscardCheckpoint(checkpointStateHandles.removeFirst());</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   LOG.debug(<span class="string">"Added &#123;&#125; to &#123;&#125;."</span>, checkpoint, path);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简要概括其逻辑：</p>
<ul>
<li>在本地磁盘存储该 checkpoint 的内容并返回句柄对象：StateHandle</li>
<li>以 checkpoint id 在 zk 上新建一个 node，并存储对应的序列化后的 StateHandle</li>
<li>检查存储的 checkpoint 个数是否超过限制，如果超过，删除本地磁盘及zk上最旧的数据</li>
<li>如果添加失败，已有的 checkpoint 数据不会受影响，这里 flink 想最大化保留作业的 checkpoint</li>
</ul>
<h3 id="从-checkpoint-中恢复"><a href="#从-checkpoint-中恢复" class="headerlink" title="从 checkpoint 中恢复"></a>从 checkpoint 中恢复</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ZooKeeperCompletedCheckpointStore line137</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">recover</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">   LOG.info(<span class="string">"Recovering checkpoints from ZooKeeper."</span>);</div><div class="line"></div><div class="line">   <span class="comment">// Clear local handles in order to prevent duplicates on</span></div><div class="line">   <span class="comment">// recovery. The local handles should reflect the state</span></div><div class="line">   <span class="comment">// of ZooKeeper.</span></div><div class="line">   checkpointStateHandles.clear();</div><div class="line"></div><div class="line">   <span class="comment">// Get all there is first</span></div><div class="line">   List&lt;Tuple2&lt;StateHandle&lt;CompletedCheckpoint&gt;, String&gt;&gt; initialCheckpoints;</div><div class="line">   <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">         initialCheckpoints = checkpointsInZooKeeper.getAllSortedByName();</div><div class="line">         <span class="keyword">break</span>;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">catch</span> (ConcurrentModificationException e) &#123;</div><div class="line">         LOG.warn(<span class="string">"Concurrent modification while reading from ZooKeeper. Retrying."</span>);</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">int</span> numberOfInitialCheckpoints = initialCheckpoints.size();</div><div class="line"></div><div class="line">   LOG.info(<span class="string">"Found &#123;&#125; checkpoints in ZooKeeper."</span>, numberOfInitialCheckpoints);</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (numberOfInitialCheckpoints &gt; <span class="number">0</span>) &#123;</div><div class="line">      <span class="comment">// Take the last one. This is the latest checkpoints, because path names are strictly</span></div><div class="line">      <span class="comment">// increasing (checkpoint ID).</span></div><div class="line">      Tuple2&lt;StateHandle&lt;CompletedCheckpoint&gt;, String&gt; latest = initialCheckpoints</div><div class="line">            .get(numberOfInitialCheckpoints - <span class="number">1</span>);</div><div class="line"></div><div class="line">      CompletedCheckpoint latestCheckpoint = latest.f0.getState(userClassLoader);</div><div class="line"></div><div class="line">      checkpointStateHandles.add(latest);</div><div class="line"></div><div class="line">      LOG.info(<span class="string">"Initialized with &#123;&#125;. Removing all older checkpoints."</span>, latestCheckpoint);</div><div class="line"></div><div class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numberOfInitialCheckpoints - <span class="number">1</span>; i++) &#123;</div><div class="line">         <span class="keyword">try</span> &#123;</div><div class="line">            removeFromZooKeeperAndDiscardCheckpoint(initialCheckpoints.get(i));</div><div class="line">         &#125;</div><div class="line">         <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            LOG.error(<span class="string">"Failed to discard checkpoint"</span>, e);</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简要概括其逻辑：</p>
<ul>
<li>清除内存中维护的句柄对象 StateHandle s</li>
<li>从 ZK 上拉取作业对应的所有的 checkpoint StateHandle 节点，并排序【从小到大】</li>
<li>获取最新的一次快照并从本地磁盘恢复 checkpoint</li>
<li>删除其余所有的 checkpoint 信息【ZK 和本地磁盘】</li>
</ul>
<p>ZooKeeperCompletedCheckpointStore 由 ZooKeeperCheckpointRecoveryFactory 负责实例化，一个 Job 会实例化一个 ZooKeeperCompletedCheckpointStore 负责快照。这里存储的只是个节点快照的句柄，并不是真正的状态数据。</p>
<p>具体的启动流程见 JobManager</p>
<p><code>line1208 val completedCheckpoints = checkpointRecoveryFactory.createCheckpointStore(jobId, userCodeLoader)</code></p>
<p><code>line1238 executionGraph.enableSnapshotCheckpointing</code></p>
<p>到这里 JobManager 的核心组件基本就介绍结束了😄</p>
]]></content>
    
    <summary type="html">
    
      JobManager 是 flink 集群的中控节点，类似于 Apache Storm 的 Nimbus 以及 Apache Spark 的 Driver 的角色，它负责作业的调度、jar 包管理、checkpoint 的协调和发起等，为了后续章节的开展，本文将介绍 flink JobManager 中所部署的一些服务
    
    </summary>
    
      <category term="Streaming" scheme="https://danny0405.github.io/categories/Streaming/"/>
    
    
      <category term="flink" scheme="https://danny0405.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink 物理计划生成</title>
    <link href="https://danny0405.github.io/2017/02/06/flink%E7%89%A9%E7%90%86%E8%AE%A1%E5%88%92%E7%94%9F%E6%88%90/"/>
    <id>https://danny0405.github.io/2017/02/06/flink物理计划生成/</id>
    <published>2017-02-06T09:12:21.000Z</published>
    <updated>2017-02-06T10:52:19.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上一节讲到业务代码<code>StreamExecutionEnvironment.execute()</code>会触发job的客户端逻辑计划<code>JobGraph</code> 的生成，之后是客户端与<code>JobManager</code>的交互过程</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ClusterClient line388</span></div><div class="line"><span class="function"><span class="keyword">public</span> JobExecutionResult <span class="title">run</span><span class="params">(JobGraph jobGraph, ClassLoader classLoader)</span> <span class="keyword">throws</span> ProgramInvocationException </span>&#123;</div><div class="line"></div><div class="line">   waitForClusterToBeReady();</div><div class="line"></div><div class="line">   <span class="keyword">final</span> LeaderRetrievalService leaderRetrievalService;</div><div class="line">   <span class="keyword">try</span> &#123;</div><div class="line">      leaderRetrievalService = LeaderRetrievalUtils.createLeaderRetrievalService(flinkConfig);</div><div class="line">   &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ProgramInvocationException(<span class="string">"Could not create the leader retrieval service"</span>, e);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">try</span> &#123;</div><div class="line">      logAndSysout(<span class="string">"Submitting job with JobID: "</span> + jobGraph.getJobID() + <span class="string">". Waiting for job completion."</span>);</div><div class="line">      <span class="keyword">this</span>.lastJobExecutionResult = JobClient.submitJobAndWait(actorSystemLoader.get(),</div><div class="line">         leaderRetrievalService, jobGraph, timeout, printStatusDuringExecution, classLoader);</div><div class="line">      <span class="keyword">return</span> <span class="keyword">this</span>.lastJobExecutionResult;</div><div class="line">   &#125; <span class="keyword">catch</span> (JobExecutionException e) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ProgramInvocationException(<span class="string">"The program execution failed: "</span> + e.getMessage(), e);</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其中<code>leaderRetrievalService = LeaderRetrievalUtils.createLeaderRetrievalService(flinkConfig);</code>是启动获取 leader JobManager 的服务，flink 支持 JobManager HA，需要通过 leader JobManager 获取当前的 leader JobManager，稍微介绍下这个服务：</p>
<h2 id="JobManager-Leader-选举"><a href="#JobManager-Leader-选举" class="headerlink" title="JobManager Leader 选举"></a>JobManager Leader 选举</h2><p>先来看获取 <code>LeaderRetrievalService</code>的逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//LeaderRetrievalUtils line61</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> LeaderRetrievalService <span class="title">createLeaderRetrievalService</span><span class="params">(Configuration configuration)</span></span></div><div class="line">   <span class="keyword">throws</span> Exception &#123;</div><div class="line"></div><div class="line">   RecoveryMode recoveryMode = getRecoveryMode(configuration);</div><div class="line"></div><div class="line">   <span class="keyword">switch</span> (recoveryMode) &#123;</div><div class="line">      <span class="keyword">case</span> STANDALONE:</div><div class="line">         <span class="keyword">return</span> StandaloneUtils.createLeaderRetrievalService(configuration);</div><div class="line">      <span class="keyword">case</span> ZOOKEEPER:</div><div class="line">         <span class="keyword">return</span> ZooKeeperUtils.createLeaderRetrievalService(configuration);</div><div class="line">      <span class="keyword">default</span>:</div><div class="line">         <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">"Recovery mode "</span> + recoveryMode + <span class="string">" is not supported."</span>);</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>首先 flink 会依据配置获取 <code>RecoveryMode</code>，<code>RecoveryMode</code>一共两种：<em>STANDALONE</em>和<em>ZOOKEEPER</em>。如果用户配置的是<em>STANDALONE</em>，会直接去配置中获取<code>JobManager</code>的地址，这里主要介绍<code>ZOOKEEPER</code>模式下的<code>JobManager</code>leader的发现过程：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ZooKeeperUtils line141</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ZooKeeperLeaderRetrievalService <span class="title">createLeaderRetrievalService</span><span class="params">(</span></span></div><div class="line">      Configuration configuration) <span class="keyword">throws</span> Exception &#123;</div><div class="line">   CuratorFramework client = startCuratorFramework(configuration);</div><div class="line">   String leaderPath = configuration.getString(ConfigConstants.ZOOKEEPER_LEADER_PATH,</div><div class="line">         ConfigConstants.DEFAULT_ZOOKEEPER_LEADER_PATH);</div><div class="line"></div><div class="line">   <span class="keyword">return</span> <span class="keyword">new</span> ZooKeeperLeaderRetrievalService(client, leaderPath);</div><div class="line">&#125;</div><div class="line"></div><div class="line">...</div><div class="line"><span class="comment">//ZooKeeperLeaderRetrievalService line103</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nodeChanged</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			LOG.debug(<span class="string">"Leader node has changed."</span>);</div><div class="line"></div><div class="line">			ChildData childData = cache.getCurrentData();</div><div class="line"></div><div class="line">			String leaderAddress;</div><div class="line">			UUID leaderSessionID;</div><div class="line"></div><div class="line">			<span class="keyword">if</span> (childData == <span class="keyword">null</span>) &#123;</div><div class="line">				leaderAddress = <span class="keyword">null</span>;</div><div class="line">				leaderSessionID = <span class="keyword">null</span>;</div><div class="line">			&#125; <span class="keyword">else</span> &#123;</div><div class="line">				<span class="keyword">byte</span>[] data = childData.getData();</div><div class="line"></div><div class="line">				<span class="keyword">if</span> (data == <span class="keyword">null</span> || data.length == <span class="number">0</span>) &#123;</div><div class="line">					leaderAddress = <span class="keyword">null</span>;</div><div class="line">					leaderSessionID = <span class="keyword">null</span>;</div><div class="line">				&#125; <span class="keyword">else</span> &#123;</div><div class="line">					ByteArrayInputStream bais = <span class="keyword">new</span> ByteArrayInputStream(data);</div><div class="line">					ObjectInputStream ois = <span class="keyword">new</span> ObjectInputStream(bais);</div><div class="line"></div><div class="line">					leaderAddress = ois.readUTF();</div><div class="line">					leaderSessionID = (UUID) ois.readObject();</div></pre></td></tr></table></figure>
<p>这里 flink 会首先尝试连接 zookeeper，利用 zookeeper的leader选举服务发现leader节点的地址和当前的 sessionid，session id的作用介绍<code>JobManager</code>的时候会详细说明</p>
<h2 id="客户端JobGraph的提交"><a href="#客户端JobGraph的提交" class="headerlink" title="客户端JobGraph的提交"></a>客户端JobGraph的提交</h2><p>客户端的<code>JobGraph</code>生成之后，通过上面的<code>LeaderRetrivalService</code>获取<code>JobManager</code>的地址，接下来就是将<code>JobGraph</code>提交给<code>JobManager</code>去执行。flink 的核心进程通信是通过 Akka 来完成的，<code>JobManager</code>、<code>TaskManager</code>都是一个 Akka system，所以这里的提交首先需要生成一个客户端actor与<code>JobManager</code>交互，然后执行rpc命令，具体见：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//JobClient line98</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> JobExecutionResult <span class="title">submitJobAndWait</span><span class="params">(</span></span></div><div class="line">      ActorSystem actorSystem,</div><div class="line">      LeaderRetrievalService leaderRetrievalService,</div><div class="line">      JobGraph jobGraph,</div><div class="line">      FiniteDuration timeout,</div><div class="line">      <span class="keyword">boolean</span> sysoutLogUpdates,</div><div class="line">      ClassLoader classLoader) <span class="keyword">throws</span> JobExecutionException &#123;</div><div class="line"></div><div class="line">   ...</div><div class="line"></div><div class="line">   <span class="comment">// for this job, we create a proxy JobClientActor that deals with all communication with</span></div><div class="line">   <span class="comment">// the JobManager. It forwards the job submission, checks the success/failure responses, logs</span></div><div class="line">   <span class="comment">// update messages, watches for disconnect between client and JobManager, ...</span></div><div class="line"></div><div class="line">   Props jobClientActorProps = JobClientActor.createJobClientActorProps(</div><div class="line">      leaderRetrievalService,</div><div class="line">      timeout,</div><div class="line">      sysoutLogUpdates);</div><div class="line"></div><div class="line">   ActorRef jobClientActor = actorSystem.actorOf(jobClientActorProps);</div><div class="line"></div><div class="line">   <span class="comment">// first block handles errors while waiting for the result</span></div><div class="line">   Object answer;</div><div class="line">   <span class="keyword">try</span> &#123;</div><div class="line">      Future&lt;Object&gt; future = Patterns.ask(jobClientActor,</div><div class="line">            <span class="keyword">new</span> JobClientMessages.SubmitJobAndWait(jobGraph),</div><div class="line">            <span class="keyword">new</span> Timeout(AkkaUtils.INF_TIMEOUT()));</div><div class="line"></div><div class="line">      answer = Await.result(future, AkkaUtils.INF_TIMEOUT());</div><div class="line">   &#125;</div><div class="line">   ...</div></pre></td></tr></table></figure>
<p>在<code>JobClientActor</code>启动之前会启动<code>LeaderRetrivalService</code>，<code>LeaderRetrivalService</code>启动之后会通知它的 Listener <code>JobClientActor</code>获取<code>JobManager</code>的地址和当前 session id。之后经过消息路由跳转到提交的核心逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//JobClientActor line354</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">tryToSubmitJob</span><span class="params">(<span class="keyword">final</span> JobGraph jobGraph)</span> </span>&#123;</div><div class="line">   <span class="keyword">this</span>.jobGraph = jobGraph;</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (isConnected()) &#123;</div><div class="line">      LOG.info(<span class="string">"Sending message to JobManager &#123;&#125; to submit job &#123;&#125; (&#123;&#125;) and wait for progress"</span>,</div><div class="line">         jobManager.path().toString(), jobGraph.getName(), jobGraph.getJobID());</div><div class="line"></div><div class="line">      Futures.future(<span class="keyword">new</span> Callable&lt;Object&gt;() &#123;</div><div class="line">         <span class="meta">@Override</span></div><div class="line">         <span class="function"><span class="keyword">public</span> Object <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">            ActorGateway jobManagerGateway = <span class="keyword">new</span> AkkaActorGateway(jobManager, leaderSessionID);</div><div class="line"></div><div class="line">            LOG.info(<span class="string">"Upload jar files to job manager &#123;&#125;."</span>, jobManager.path());</div><div class="line"></div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">               jobGraph.uploadUserJars(jobManagerGateway, timeout);</div></pre></td></tr></table></figure>
<p>上面的代码有所省略😝。</p>
<p>总结下上面的过程：</p>
<img src="/2017/02/06/flink物理计划生成/jobclient-to-jobmanager.png" alt="jobclient-to-jobmanager" title="jobclient-to-jobmanager">
<ul>
<li>启动<code>JobClientActor</code>用来和<code>JobManager</code>交互</li>
<li>启动<code>LeaderRetrievalService</code>获取<code>JobManager</code>的地址</li>
<li>上传用户 jar 包</li>
<li>提交 SubmitJob 命令</li>
</ul>
<h2 id="JobManager执行计划生成"><a href="#JobManager执行计划生成" class="headerlink" title="JobManager执行计划生成"></a>JobManager执行计划生成</h2><p><code>JobManager</code>负责接收 flink 的作业，调度 task，收集 job 的状态、管理 TaskManagers。被实现为一个 akka actor。</p>
<p>客户端上传完 jar 包和<code>JobGraph</code>，flink 会进一步解析封装成运行时的执行计划<code>ExecutionGraph</code>，<code>JobManager</code>的构造器在初始化的时候传入了很多组件，这里简单列举下功能方便后面的逻辑展开，具体的细节将会在下一节讲解。</p>
<ul>
<li><code>BlobServer</code>：实现了 BOLB server，其会监听收到的 requests，并会创建 目录结构存储 BLOBS 【持久化】或者临时性的缓存他们</li>
<li><code>InstanceManager</code>：TaskManager在<code>flink</code>框架内部被叫做<code>Instance</code>，flink通过<code>InstanceManager</code>管理 flink 集群中当前所有活跃的 TaskManager，包括接收心跳，通知 InstanceListener Instance 的生成与死亡，一个典型的 <code>InstanceListener</code> 为 flink 的 Scheduler</li>
<li><code>BlobLibraryCacheManager</code>：flink job 的 jar 包存储服务，使用上面的 BlobServer 完成。</li>
<li><code>MemoryArchivist</code>备案已提交的flink作业，包括<code>JobGraph</code>、<code>ExecutionGraph</code>等</li>
<li>​</li>
<li><code>ZooKeeperCompletedCheckpointStore</code>：负责持久化 job 的 checkpoint 信息，一个 job 可以持久化多个 checkpoint，但只有最新的会被使用，具体方式为先在文件系统中持久化一份，再将文件句柄更新到 zk，并在 zk上依次递增节点路径号，zk 上保存了最近的 10 次 checkpoint</li>
<li>SavepointStore：flink 的状态存储，负责存储算子内部定义的状态，与 checkpoint 稍有区别，后者由 flink 框架来维护</li>
</ul>
<p><em>为了对<code>JobManager</code>中所起的 actors 服务有所了解，这里简单介绍下<code>JobManager</code>的启动过程</em></p>
<p>简单分析得知<code>line2049: runJobManager</code>是JobManager启动的入口，在获取<code>JobManager</code>启动的主机和端口后，变开始启动 actor system，web ui以及其他 actors：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//JobManager line2008</span></div><div class="line"><span class="function">def <span class="title">runJobManager</span><span class="params">(</span></span></div><div class="line">    configuration: Configuration,</div><div class="line">    executionMode: JobManagerMode,</div><div class="line">    listeningAddress: String,</div><div class="line">    listeningPort: Int)</div><div class="line">  : Unit = &#123;</div><div class="line"></div><div class="line">  val (jobManagerSystem, _, _, webMonitorOption, _) = startActorSystemAndJobManagerActors(</div><div class="line">    configuration,</div><div class="line">    executionMode,</div><div class="line">    listeningAddress,</div><div class="line">    listeningPort,</div><div class="line">    classOf[JobManager],</div><div class="line">    classOf[MemoryArchivist],</div><div class="line">    Option(classOf[StandaloneResourceManager])</div><div class="line">  )</div><div class="line"></div><div class="line">  <span class="comment">// block until everything is shut down</span></div><div class="line">  jobManagerSystem.awaitTermination()</div></pre></td></tr></table></figure>
<p>具体的启动逻辑在<code>startActorSystemAndJobManagerActors</code>方法中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//JobManager line2150</span></div><div class="line"><span class="function">def <span class="title">startActorSystemAndJobManagerActors</span><span class="params">(</span></span></div><div class="line">    configuration: Configuration,</div><div class="line">    executionMode: JobManagerMode,</div><div class="line">    listeningAddress: String,</div><div class="line">    listeningPort: Int,</div><div class="line">    jobManagerClass: Class[_ &lt;: JobManager],</div><div class="line">    archiveClass: Class[_ &lt;: MemoryArchivist],</div><div class="line">    resourceManagerClass: Option[Class[_ &lt;: FlinkResourceManager[_]]])</div><div class="line">  : <span class="params">(ActorSystem, ActorRef, ActorRef, Option[WebMonitor], Option[ActorRef])</span> = &#123;</div><div class="line">  ...</div></pre></td></tr></table></figure>
<p>简单列举下逻辑：</p>
<ul>
<li>JobManager 程序的主入口，由 ApplicationMasterBase 发起</li>
<li>line 2174 使用 Json 配置 Akka 并生成 ActorSystem</li>
<li>line 2197 初始化 ZooKeeperLeaderRetrievalService，JobManager在启动的时候会以 LeaderRetrievalListener 的身份将自己注册进来，该 service 负责监听最新的 leader 信息，当发生改变时 通知所有 listener【所有的 JobManager】</li>
<li>line 2220 启动 YarnJobManager 和 MemoryArchivist actors【这里并没有启动】</li>
<li>line2268 启动【flink基本组件和JobGraph的生成一节中提到的】FlinkResourceManager</li>
<li>line 2620 createJobManagerComponents 获取以上两个组件必要的配置，并初始化相关服务 具体见【 flink JobManager 中所起的服务】这里在初始化相关组件后会初始化 JobManager，akka actorOf 方法传入的属性为构造器中参数，重载 preStart 和 postStop 方法会在 actor 启动和关闭后 相继执行，JobManager 会在这两个方法中启动和停止这些服务</li>
</ul>
<p>到这里一个完整的<code>JobManager</code> actor 便启动起来了😜</p>
<p>既然是 actor ，那么他的核心逻辑一定是各种消息的路由和处理：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//JobManager line304</span></div><div class="line">override def handleMessage: Receive = &#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">case</span> <span class="title">GrantLeadership</span><span class="params">(newLeaderSessionID)</span> </span>=&gt;</div><div class="line">    log.info(s<span class="string">"JobManager $getAddress was granted leadership with leader session ID "</span> +</div><div class="line">      s<span class="string">"$newLeaderSessionID."</span>)</div><div class="line"></div><div class="line">    leaderSessionID = newLeaderSessionID</div></pre></td></tr></table></figure>
<p>介绍下这里比较重要的几种消息：</p>
<ul>
<li>处理消息的核心方法</li>
<li>GrantLeadership 获得leader授权，将自身被分发到的 session id 写到 zookeeper，并恢复所有的 jobs.</li>
<li>RevokeLeadership 剥夺leader授权，打断清空所有的 job 信息，但是保留作业缓存，注销所有的 TaskManagers. </li>
<li>RegisterTaskManagers 注册 TaskManager，如果之前已经注册过，则只给对应的 Instance 发送消息，否则启动注册逻辑：在 InstanceManager 中注册该 Instance 的信息，并停止 Instance BlobLibraryCacheManager 的端口【供下载 lib 包用】，同时使用 watch 监听 task manager 的存活</li>
<li>SubmitJob 提交 jobGraph</li>
</ul>
<h3 id="执行计划-ExecutionGraph-的生成"><a href="#执行计划-ExecutionGraph-的生成" class="headerlink" title="执行计划 ExecutionGraph 的生成"></a>执行计划 ExecutionGraph 的生成</h3><p>flink 的运行时执行计划为 ExecutionGraph，ExecutionGraph 对应之前的 JobGraph，一个 ExecutionGraph 包含多个 ExecutionJobVertex 节点，JobGraph 的 JobVertex，每个 ExecutionJobVertex 节点的并发子 task 对应一个 ExecutionVertex，每个 ExecutionVertex 的一次 attempt 执行被抽象为一次 Execution，具体如下图所示：</p>
<img src="/2017/02/06/flink物理计划生成/flink-job-vertex-to-execution.png" alt="flink-job-vertex-to-execution.png" title="flink-job-vertex-to-execution.png">
<p><em>下面会对每个抽象做详细的介绍</em></p>
<p>ExecutionGraph 的创建是在 JobManager 接收 SubmitJob 命令后开始的，这条消息会被路由到方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//JobManager line1048</span></div><div class="line"><span class="function"><span class="keyword">private</span> def <span class="title">submitJob</span><span class="params">(jobGraph: JobGraph, jobInfo: JobInfo, isRecovery: Boolean = <span class="keyword">false</span>)</span>: Unit </span>= &#123;</div><div class="line">  <span class="keyword">if</span> (jobGraph == <span class="keyword">null</span>) &#123;</div><div class="line">    jobInfo.client ! decorateMessage(JobResultFailure(</div><div class="line">      <span class="keyword">new</span> SerializedThrowable(</div><div class="line">        <span class="keyword">new</span> JobSubmissionException(<span class="keyword">null</span>, <span class="string">"JobGraph must not be null."</span>)</div><div class="line">      )</div><div class="line">    ))</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>其逻辑总结如下：</p>
<ul>
<li>提交作业</li>
<li>具体的组件交互过程 Client.java line169 runBlocking -&gt; JobClient.java line102 submitJobAndWait -&gt; JobClientActor.java line 337 tryToSubmitJob  这里会先上传 jars 到 JobManager 的 BlobServer，然后发起提交命令</li>
<li>line1068: 设置用户lib包，使用  LibraryCacheManager book job 的jar包，由于之前包已上传，这会创建jobId 和 jars 以及class paths 的对应关系</li>
<li>line1114: 将 JobGraph 转换为 ExecutionGraph 逻辑计划转化为物理计划【后者维护 data flow 的协调执行、连接、计算中间结果】具体见章节： flink runtime</li>
<li>line 1178 ExecutionJobVertex 在此处生成，通过 JobGraph 依照数据源顺序获取下游 JobVertex，具体算法如下：</li>
</ul>
<img src="/2017/02/06/flink物理计划生成/job-graph-node-sort.png" alt="job-graph-node-sort.png" title="job-graph-node-sort.png">
<p>flink排序节点的顺序：</p>
<ul>
<li>数据源节点</li>
<li>只有一个上游的节点</li>
<li>sink节点</li>
</ul>
<p><em>例如上图的两个拓扑结构，左边节点排序完的顺序为： 1 2 3 4 5 右边的节点排序完的顺序为：1 2 3 5 4 6</em></p>
<p>那么 flink 为什么要将 JobGraph 转换为 ExecutionGraph ，并且排序这些节点呢？ExecutionGraph 代表了运行时的执行计划，包括 task 的并发、连接、中间结果的维护等，排序的目的是给 task 的部署设置先后顺序，想来也是很自然的。我们来看一下 ExecutionGraph 的构造器就能了解个大概：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">ExecutionGraph</span><span class="params">(</span></span></div><div class="line">      ExecutionContext executionContext,</div><div class="line">      JobID jobId,</div><div class="line">      String jobName,</div><div class="line">      Configuration jobConfig,</div><div class="line">      SerializedValue&lt;ExecutionConfig&gt; serializedConfig,</div><div class="line">      FiniteDuration timeout,</div><div class="line">      RestartStrategy restartStrategy,</div><div class="line">      List&lt;BlobKey&gt; requiredJarFiles,</div><div class="line">      List&lt;URL&gt; requiredClasspaths,</div><div class="line">      ClassLoader userClassLoader,</div><div class="line">      MetricGroup metricGroup) &#123;</div><div class="line"></div><div class="line">   ...</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.executionContext = executionContext;</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.jobID = jobId;</div><div class="line">   <span class="keyword">this</span>.jobName = jobName;</div><div class="line">   <span class="keyword">this</span>.jobConfiguration = jobConfig;</div><div class="line">   <span class="keyword">this</span>.userClassLoader = userClassLoader;</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.tasks = <span class="keyword">new</span> ConcurrentHashMap&lt;JobVertexID, ExecutionJobVertex&gt;();</div><div class="line">   <span class="keyword">this</span>.intermediateResults = <span class="keyword">new</span> ConcurrentHashMap&lt;IntermediateDataSetID, IntermediateResult&gt;();</div><div class="line">   <span class="keyword">this</span>.verticesInCreationOrder = <span class="keyword">new</span> ArrayList&lt;ExecutionJobVertex&gt;();</div><div class="line">   <span class="keyword">this</span>.currentExecutions = <span class="keyword">new</span> ConcurrentHashMap&lt;ExecutionAttemptID, Execution&gt;();</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.jobStatusListenerActors  = <span class="keyword">new</span> CopyOnWriteArrayList&lt;ActorGateway&gt;();</div><div class="line">   <span class="keyword">this</span>.executionListenerActors = <span class="keyword">new</span> CopyOnWriteArrayList&lt;ActorGateway&gt;();</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.stateTimestamps = <span class="keyword">new</span> <span class="keyword">long</span>[JobStatus.values().length];</div><div class="line">   <span class="keyword">this</span>.stateTimestamps[JobStatus.CREATED.ordinal()] = System.currentTimeMillis();</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.requiredJarFiles = requiredJarFiles;</div><div class="line">   <span class="keyword">this</span>.requiredClasspaths = requiredClasspaths;</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.serializedExecutionConfig = checkNotNull(serializedConfig);</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.timeout = timeout;</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.restartStrategy = restartStrategy;</div><div class="line"></div><div class="line">   metricGroup.gauge(RESTARTING_TIME_METRIC_NAME, <span class="keyword">new</span> RestartTimeGauge());</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从构造器可以看出，ExecutionGraph 会维护当前的逻辑计划信息【就是有哪些task要执行】、中间结果生成信息，当前正在运行的 task，负责 job 和 task 状态切换的通知等。</p>
<h4 id="执行计划节点-ExecutionJobVertex-的生成"><a href="#执行计划节点-ExecutionJobVertex-的生成" class="headerlink" title="执行计划节点 ExecutionJobVertex 的生成"></a>执行计划节点 ExecutionJobVertex 的生成</h4><p>attachJobGraph 是 ExecutionGraph 构造图结构的核心方法，而其中最关键的逻辑是 执行节点 ExecutionJobGraph 的创建，下面详细分析下其创建过程和核心功能：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ExecutionJobVertex line95</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">ExecutionJobVertex</span><span class="params">(ExecutionGraph graph, JobVertex jobVertex,</span></span></div><div class="line">                  <span class="keyword">int</span> defaultParallelism, FiniteDuration timeout, <span class="keyword">long</span> createTimestamp)</div><div class="line">      <span class="keyword">throws</span> JobException</div><div class="line">&#123;</div><div class="line">   ...</div><div class="line">   <span class="keyword">this</span>.graph = graph;</div><div class="line">   <span class="keyword">this</span>.jobVertex = jobVertex;</div><div class="line"></div><div class="line">   <span class="keyword">int</span> vertexParallelism = jobVertex.getParallelism();</div><div class="line">   <span class="keyword">int</span> numTaskVertices = vertexParallelism &gt; <span class="number">0</span> ? vertexParallelism : defaultParallelism;</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.parallelism = numTaskVertices;</div><div class="line">   <span class="keyword">this</span>.taskVertices = <span class="keyword">new</span> ExecutionVertex[numTaskVertices];</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.inputs = <span class="keyword">new</span> ArrayList&lt;IntermediateResult&gt;(jobVertex.getInputs().size());</div><div class="line"></div><div class="line">   <span class="comment">// take the sharing group</span></div><div class="line">   <span class="keyword">this</span>.slotSharingGroup = jobVertex.getSlotSharingGroup();</div><div class="line">   <span class="keyword">this</span>.coLocationGroup = jobVertex.getCoLocationGroup();</div><div class="line">   ...</div><div class="line"></div><div class="line">   <span class="comment">// create the intermediate results</span></div><div class="line">   <span class="keyword">this</span>.producedDataSets = <span class="keyword">new</span> IntermediateResult[jobVertex.getNumberOfProducedIntermediateDataSets()];</div><div class="line"></div><div class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; jobVertex.getProducedDataSets().size(); i++) &#123;</div><div class="line">      <span class="keyword">final</span> IntermediateDataSet result = jobVertex.getProducedDataSets().get(i);</div><div class="line"></div><div class="line">      <span class="keyword">this</span>.producedDataSets[i] = <span class="keyword">new</span> IntermediateResult(</div><div class="line">            result.getId(),</div><div class="line">            <span class="keyword">this</span>,</div><div class="line">            numTaskVertices,</div><div class="line">            result.getResultType(),</div><div class="line">            result.getEagerlyDeployConsumers());</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="comment">// create all task vertices</span></div><div class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numTaskVertices; i++) &#123;</div><div class="line">      ExecutionVertex vertex = <span class="keyword">new</span> ExecutionVertex(<span class="keyword">this</span>, i, <span class="keyword">this</span>.producedDataSets, timeout, createTimestamp);</div><div class="line">      <span class="keyword">this</span>.taskVertices[i] = vertex;</div><div class="line">   &#125;</div><div class="line">   ...</div><div class="line"></div><div class="line">   <span class="comment">// set up the input splits, if the vertex has any</span></div><div class="line">   <span class="keyword">try</span> &#123;</div><div class="line">      <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</div><div class="line">      InputSplitSource&lt;InputSplit&gt; splitSource = (InputSplitSource&lt;InputSplit&gt;) jobVertex.getInputSplitSource();</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (splitSource != <span class="keyword">null</span>) &#123;</div><div class="line">         inputSplits = splitSource.createInputSplits(numTaskVertices);</div><div class="line"></div><div class="line">         <span class="keyword">if</span> (inputSplits != <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="keyword">if</span> (splitSource <span class="keyword">instanceof</span> StrictlyLocalAssignment) &#123;</div><div class="line">               inputSplitsPerSubtask = computeLocalInputSplitsPerTask(inputSplits);</div><div class="line">               splitAssigner = <span class="keyword">new</span> PredeterminedInputSplitAssigner(inputSplitsPerSubtask);</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">               splitAssigner = splitSource.getInputSplitAssigner(inputSplits);</div><div class="line">            &#125;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">else</span> &#123;</div><div class="line">         inputSplits = <span class="keyword">null</span>;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">   <span class="keyword">catch</span> (Throwable t) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> JobException(<span class="string">"Creating the input splits caused an error: "</span> + t.getMessage(), t);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   finishedSubtasks = <span class="keyword">new</span> <span class="keyword">boolean</span>[parallelism];</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简要介绍下其构建逻辑：</p>
<ul>
<li>依据对应的 JobVetex 的并发生成对应个数的 ExecutionVertex，一个 ExecutionVertex 代表一个 ExecutionJobVertex 的并发子 task</li>
<li>设置 SlotSharingGroup 和 CoLocationGroup，这两个组件是 flink 运行时任务调度的核心抽象，会约束 flink 调度 task 的策略，在 flink 任务调度算法 一节会详细介绍</li>
<li>将原来 JobVertex 的中间结果 IntermediateDataSet 转化为 IntermediateResult，后者在前者的基础上加入了 当前正在运行的 producer 信息，是真正关于运行时中间数据的抽象</li>
<li>如果对应的 job 节点是数据源节点，会获取其 InputSplitSource，InputSplitSource 控制了数据源并发子 task 和生产的 InputSplit 的对应关系，一个 InputSplit 代表一个数据源分片，对于 flink streaming 来说，InputSplitSource 就是一个 InputFormat，对应一个输入源 task</li>
<li>这里的 InputSplitSource 是在什么时候设置进去的呢？见<code>JobManager line1163 vertex.initializeOnMaster(userCodeLoader)</code>以及<code>StreamingJobGraphGenerator.java line 278 createDataSourceVertex</code></li>
</ul>
<h4 id="执行计划节点-ExecutionJobVertex-的连接"><a href="#执行计划节点-ExecutionJobVertex-的连接" class="headerlink" title="执行计划节点 ExecutionJobVertex 的连接"></a>执行计划节点 ExecutionJobVertex 的连接</h4><p>构建完节点后通过连接生成执行计划 DAG【见ExecutionGraph attachJobGraph 方法】，connectToPredecessors 是连接执行节点的核心逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ExecutionJobGraph line237</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connectToPredecessors</span><span class="params">(Map&lt;IntermediateDataSetID, IntermediateResult&gt; intermediateDataSets)</span> <span class="keyword">throws</span> JobException </span>&#123;</div><div class="line"></div><div class="line">   List&lt;JobEdge&gt; inputs = jobVertex.getInputs();</div><div class="line"></div><div class="line">   ...</div><div class="line"></div><div class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> num = <span class="number">0</span>; num &lt; inputs.size(); num++) &#123;</div><div class="line">      JobEdge edge = inputs.get(num);</div><div class="line"></div><div class="line">      ...</div><div class="line"></div><div class="line">      <span class="comment">// fetch the intermediate result via ID. if it does not exist, then it either has not been created, or the order</span></div><div class="line">      <span class="comment">// in which this method is called for the job vertices is not a topological order</span></div><div class="line">      IntermediateResult ires = intermediateDataSets.get(edge.getSourceId());</div><div class="line">      <span class="keyword">if</span> (ires == <span class="keyword">null</span>) &#123;</div><div class="line">         <span class="keyword">throw</span> <span class="keyword">new</span> JobException(<span class="string">"Cannot connect this job graph to the previous graph. No previous intermediate result found for ID "</span></div><div class="line">               + edge.getSourceId());</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">this</span>.inputs.add(ires);</div><div class="line"></div><div class="line">      <span class="keyword">int</span> consumerIndex = ires.registerConsumer();</div><div class="line"></div><div class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; parallelism; i++) &#123;</div><div class="line">         ExecutionVertex ev = taskVertices[i];</div><div class="line">         ev.connectSource(num, ires, edge, consumerIndex);</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简要概括逻辑如下：</p>
<ul>
<li>设置输入 IntermediateResult</li>
<li>将自己注册到  IntermediateResult，目前一个 IntermediateResult 只支持一个 消费 ExecutionJobVertex 节点</li>
<li>设置并发子 task ExecutionVertex 和中间结果 IntermediateResult 的连接关系，通过 ExecutionVertex 的 connectSource  方法设置 ExecutionVertex 的连接策略，策略一共两种： POINT_WISE ALL_TO_ALL 前者上游 partition 与下游 consumers 之间是一对多关系，后者是 all to all 关系，这里会将 ExecutionEdge 创建出来并添加 consumer 为此 edge【partition在 new ExecutionVertex时创建出来，由 ExecutionVertex 构造器可知一个 ExecutionVertex 生产一个 partition，partition number 就是 sub task index】</li>
</ul>
<h4 id="执行节点子任务-ExecutionVertex"><a href="#执行节点子任务-ExecutionVertex" class="headerlink" title="执行节点子任务 ExecutionVertex"></a>执行节点子任务 ExecutionVertex</h4><p>先看一下 ExecutionVertex 的创建过程：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">ExecutionVertex</span><span class="params">(</span></span></div><div class="line">      ExecutionJobVertex jobVertex,</div><div class="line">      <span class="keyword">int</span> subTaskIndex,</div><div class="line">      IntermediateResult[] producedDataSets,</div><div class="line">      FiniteDuration timeout,</div><div class="line">      <span class="keyword">long</span> createTimestamp) &#123;</div><div class="line">   <span class="keyword">this</span>.jobVertex = jobVertex;</div><div class="line">   <span class="keyword">this</span>.subTaskIndex = subTaskIndex;</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.resultPartitions = <span class="keyword">new</span> LinkedHashMap&lt;IntermediateResultPartitionID, IntermediateResultPartition&gt;(producedDataSets.length, <span class="number">1</span>);</div><div class="line"></div><div class="line">   <span class="keyword">for</span> (IntermediateResult result : producedDataSets) &#123;</div><div class="line">      IntermediateResultPartition irp = <span class="keyword">new</span> IntermediateResultPartition(result, <span class="keyword">this</span>, subTaskIndex);</div><div class="line">      result.setPartition(subTaskIndex, irp);</div><div class="line"></div><div class="line">      resultPartitions.put(irp.getPartitionId(), irp);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.inputEdges = <span class="keyword">new</span> ExecutionEdge[jobVertex.getJobVertex().getInputs().size()][];</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.priorExecutions = <span class="keyword">new</span> CopyOnWriteArrayList&lt;Execution&gt;();</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.currentExecution = <span class="keyword">new</span> Execution(</div><div class="line">      getExecutionGraph().getExecutionContext(),</div><div class="line">      <span class="keyword">this</span>,</div><div class="line">      <span class="number">0</span>,</div><div class="line">      createTimestamp,</div><div class="line">      timeout);</div><div class="line"></div><div class="line">   <span class="comment">// create a co-location scheduling hint, if necessary</span></div><div class="line">   CoLocationGroup clg = jobVertex.getCoLocationGroup();</div><div class="line">   <span class="keyword">if</span> (clg != <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">this</span>.locationConstraint = clg.getLocationConstraint(subTaskIndex);</div><div class="line">   &#125;</div><div class="line">   <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">this</span>.locationConstraint = <span class="keyword">null</span>;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.timeout = timeout;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>逻辑总结如下：</p>
<ul>
<li>依据对应的 ExecutionJobGraph 生成的中间数据集 IntermediateResult 的个数生成一定个数的 partition，这里是一个 IntermediateResult 输出一个 partition</li>
<li>生成 Execution</li>
<li>配置资源相关</li>
</ul>
<p>下面重点介绍下其连接上游 ExecutionVertex 的过程：</p>
<p>connectSource 是连接的核心逻辑，逻辑如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ExecutionVertex line250</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connectSource</span><span class="params">(<span class="keyword">int</span> inputNumber, IntermediateResult source, JobEdge edge, <span class="keyword">int</span> consumerNumber)</span> </span>&#123;</div><div class="line"></div><div class="line">   <span class="keyword">final</span> DistributionPattern pattern = edge.getDistributionPattern();</div><div class="line">   <span class="keyword">final</span> IntermediateResultPartition[] sourcePartitions = source.getPartitions();</div><div class="line"></div><div class="line">   ExecutionEdge[] edges;</div><div class="line"></div><div class="line">   <span class="keyword">switch</span> (pattern) &#123;</div><div class="line">      <span class="keyword">case</span> POINTWISE:</div><div class="line">         edges = connectPointwise(sourcePartitions, inputNumber);</div><div class="line">         <span class="keyword">break</span>;</div><div class="line"></div><div class="line">      <span class="keyword">case</span> ALL_TO_ALL:</div><div class="line">         edges = connectAllToAll(sourcePartitions, inputNumber);</div><div class="line">         <span class="keyword">break</span>;</div><div class="line"></div><div class="line">      <span class="keyword">default</span>:</div><div class="line">         <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Unrecognized distribution pattern."</span>);</div><div class="line"></div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.inputEdges[inputNumber] = edges;</div><div class="line"></div><div class="line">   <span class="comment">// add the consumers to the source</span></div><div class="line">   <span class="comment">// for now (until the receiver initiated handshake is in place), we need to register the</span></div><div class="line">   <span class="comment">// edges as the execution graph</span></div><div class="line">   <span class="keyword">for</span> (ExecutionEdge ee : edges) &#123;</div><div class="line">      ee.getSource().addConsumer(ee, consumerNumber);</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>逻辑总结如下：</p>
<ul>
<li>获取 JobEdge 的数据分发策略：如果非 shuffle 操作就是 DistributionPattern.POINTWISE 否则是 DistributionPattern.ALL_TO_ALL具体见代码：</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamingJobGraphGenerator line370</span></div><div class="line">StreamPartitioner&lt;?&gt; partitioner = edge.getPartitioner();</div><div class="line"><span class="keyword">if</span> (partitioner <span class="keyword">instanceof</span> ForwardPartitioner) &#123;</div><div class="line">   downStreamVertex.connectNewDataSetAsInput(</div><div class="line">      headVertex,</div><div class="line">      DistributionPattern.POINTWISE,</div><div class="line">      ResultPartitionType.PIPELINED,</div><div class="line">      <span class="keyword">true</span>);</div><div class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (partitioner <span class="keyword">instanceof</span> RescalePartitioner)&#123;</div><div class="line">   downStreamVertex.connectNewDataSetAsInput(</div><div class="line">      headVertex,</div><div class="line">      DistributionPattern.POINTWISE,</div><div class="line">      ResultPartitionType.PIPELINED,</div><div class="line">      <span class="keyword">true</span>);</div><div class="line">&#125; <span class="keyword">else</span> &#123;</div><div class="line">   downStreamVertex.connectNewDataSetAsInput(</div><div class="line">         headVertex,</div><div class="line">         DistributionPattern.ALL_TO_ALL,</div><div class="line">         ResultPartitionType.PIPELINED,</div><div class="line">         <span class="keyword">true</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>按照不同的分发策略连接上游</li>
</ul>
<p>DistributionPattern.ALL_TO_ALL 就是简单的全连接，这里就不介绍了，只介绍DistributionPattern.POINTWISE 策略。</p>
<p>该策略连接 execution vertex 与上游的 partitions，会先获取上游的 partition 数与 此 ExecutionJobVertex 的并发度，如果两者并发度相等，则是 一对一 连接：</p>
<img src="/2017/02/06/flink物理计划生成/execution-vertex-one-to-one.png" alt="execution-vertex-one-to-one.png" title="execution-vertex-one-to-one.png">
<p>如果 partition 数小于 并发数 ，子 task 只会连接一个上游 partition，具体关系如下图：</p>
<img src="/2017/02/06/flink物理计划生成/execution-one-many.png" alt="execution-one-many.png" title="execution-one-many.png">
<p>如果 partition 数大于并发数，子 task 会连接多个上游 partition，具体见下图：</p>
<p>execution-many-one.png](execution-many-one.png)</p>
<p>到这里运行时执行计划 ExecutionGraph 的生成就介绍完了😄下节将先介绍 JobManager 的核心组件</p>
]]></content>
    
    <summary type="html">
    
      flink 物理计划生成，主要是 JobManager 运行时的抽象和管理，前一章节中有介绍过 flink 的逻辑计划抽象，在运行时，flink 进一步将逻辑计划抽象成与执行节点信息紧密相关的物理计划，来对作业的调度、执行进行管理
    
    </summary>
    
      <category term="Streaming" scheme="https://danny0405.github.io/categories/Streaming/"/>
    
    
      <category term="flink" scheme="https://danny0405.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink 基本组件/逻辑计划</title>
    <link href="https://danny0405.github.io/2016/12/03/Flink%E5%9F%BA%E6%9C%AC%E7%BB%84%E4%BB%B6%E5%92%8C%E9%80%BB%E8%BE%91%E8%AE%A1%E5%88%92/"/>
    <id>https://danny0405.github.io/2016/12/03/Flink基本组件和逻辑计划/</id>
    <published>2016-12-03T03:59:30.000Z</published>
    <updated>2017-02-06T13:38:38.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概要和背景"><a href="#概要和背景" class="headerlink" title="概要和背景"></a>概要和背景</h2><p><em>flink</em>是一个被誉为 <em>the 4th G</em> 的计算框架，不同的框架特性及其代表项目列表如下：</p>
<table>
<thead>
<tr>
<th>第一代</th>
<th>第二代</th>
<th>第三代</th>
<th>第四代</th>
</tr>
</thead>
<tbody>
<tr>
<td>Batch</td>
<td><strong>Batch</strong> <strong>Interactive</strong></td>
<td><strong>Batch</strong> <strong>Interactive</strong> <strong>Near-Real-Time</strong> <strong>Interative-processing</strong></td>
<td><strong>Hybrid</strong> <strong>Interactive</strong> <strong>Real-Time-Streaming</strong> <strong>Native-Iterative-processing</strong></td>
</tr>
<tr>
<td></td>
<td>DAG Dataflows</td>
<td>RDD</td>
<td>Cyclic Dataflows</td>
</tr>
<tr>
<td>Hadoop MapReduce</td>
<td>TEZ</td>
<td>Spark</td>
<td>Flink</td>
</tr>
</tbody>
</table>
<p>本文主要介绍<em>flink</em>的核心组件以及逻辑计划的生成过程</p>
<p><em>参考代码分支 flink-1.1.2</em></p>
<h2 id="核心组件介绍"><a href="#核心组件介绍" class="headerlink" title="核心组件介绍"></a>核心组件介绍</h2><p><em>这里只介绍 on yarn 模式下的组件</em></p>
<p><em>flink</em> 的 on yarn 模式支持两种不同的类型：</p>
<ol>
<li>单作业单集群</li>
<li>多作业单集群</li>
</ol>
<p>首先介绍 <em>单作业单集群</em> 的架构，单作业单集群下一个正常的 <em>flink</em> 程序会拥有以下组件</p>
<hr>
<p>job Cli: 非 detatched 模式下的客户端进程，用以获取 yarn Application Master 的运行状态并将日志输出掉终端</p>
<p>JobManager[JM]: 负责作业的运行时计划 ExecutionGraph 的生成、物理计划生成和作业调度</p>
<p>TaskManager[TM]: 负责被分发 task 的执行、心跳/状态上报、资源管理</p>
<hr>
<p>整体的架构大致如下图所示：</p>
<img src="/2016/12/03/Flink基本组件和逻辑计划/flink-on-yarn-arch.png" alt="flink on yarn" title="flink on yarn">
<p>下面将以一次 Job 的提交过程描述 <em>flink</em> 的各组件的作用及协同</p>
<h3 id="作业提交流程分析"><a href="#作业提交流程分析" class="headerlink" title="作业提交流程分析"></a>作业提交流程分析</h3><p>单作业单集群模式下，一个作业会启动一个 JM，并依据用户的参数传递启动相应数量的 TM，每个 TM 运行在 yarn 的一个 container 中，</p>
<p>一个通常的 flink on yarn 提交命令：<br><code>./bin/flink run -m yarn-cluster -yn 2 -j flink-demo-1.0.0-with-dependencies.jar —ytm 1024 -yst 4 -yjm 1024 —yarnname flink_demo_waimai_e</code><br><em>flink</em> 在收到这样一条命令后会首先通过 Cli 获取 flink 的配置，并解析命令行参数。</p>
<h4 id="配置加载"><a href="#配置加载" class="headerlink" title="配置加载"></a>配置加载</h4><p><code>CliFrontend.java</code> 是 flink 提交作业的入口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//CliFrontend line144</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">CliFrontend</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">   <span class="keyword">this</span>(getConfigurationDirectoryFromEnv());</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里会尝试加载 conf 文件夹下的所有 yaml 文件，配置文件的命名并没有强制限制</p>
<h4 id="参数解析"><a href="#参数解析" class="headerlink" title="参数解析"></a>参数解析</h4><p>解析命令行参数的第一步是路由用户的命令，然后交由<code>run</code>方法去处理</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//CliFrontend line993</span></div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">return</span> SecurityUtils.runSecured(<span class="keyword">new</span> SecurityUtils.FlinkSecuredRunner&lt;Integer&gt;() &#123;</div><div class="line">	    <span class="function">Override</span></div><div class="line">	    <span class="keyword">public</span> Integer <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</div><div class="line">	        <span class="keyword">return</span> CliFrontend.<span class="keyword">this</span>.run(params);</div><div class="line">		&#125;);</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">		<span class="keyword">return</span> handleError(e);</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<p>接下来是程序参数设置过程，<em>flink</em> 将 jar包路径和参数配置封装成了 <code>PackagedProgram</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//CliFrontend line223</span></div><div class="line">PackagedProgram program;</div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">   LOG.info(<span class="string">"Building program from JAR file"</span>);</div><div class="line">   program = buildProgram(options);</div><div class="line">&#125;</div><div class="line"><span class="keyword">catch</span> (Throwable t) &#123;</div><div class="line">   <span class="keyword">return</span> handleError(t);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="flink集群的构建"><a href="#flink集群的构建" class="headerlink" title="flink集群的构建"></a>flink集群的构建</h4><h5 id="集群类型的解析"><a href="#集群类型的解析" class="headerlink" title="集群类型的解析"></a>集群类型的解析</h5><p>获取参数后下一步就是集群的构建和部署，flink 通过 两个不同的 <code>CustomCommandLine</code> 来实现不同集群模式的解析，分别是 <code>FlinkYarnSessionCli</code>和 <code>DefaultCLI</code> 【吐槽一下 flink 类名的命名规范】解析命令行参数</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//CliFrontend line125</span></div><div class="line"><span class="keyword">static</span> &#123;</div><div class="line">   <span class="comment">/** command line interface of the YARN session, with a special initialization here</span></div><div class="line">    *  to prefix all options with y/yarn. */</div><div class="line">   loadCustomCommandLine(<span class="string">"org.apache.flink.yarn.cli.FlinkYarnSessionCli"</span>, <span class="string">"y"</span>, <span class="string">"yarn"</span>);</div><div class="line">   customCommandLine.add(<span class="keyword">new</span> DefaultCLI());</div><div class="line">&#125;</div><div class="line">...</div><div class="line"><span class="comment">//line882 这里将决定Cli的类型</span></div><div class="line">CustomCommandLine&lt;?&gt; activeCommandLine = getActiveCustomCommandLine(options.getCommandLine());</div></pre></td></tr></table></figure>
<p>那么什么时候解析成 Yarn Cluster 什么时候解析成 Standalone 呢？由于<code>FlinkYarnSessionCli</code>被优先添加到<code>customCommandLine</code>,所以会先触发下面这段逻辑</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//FlinkYarnSessionCli line469</span></div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isActive</span><span class="params">(CommandLine commandLine, Configuration configuration)</span> </span>&#123;</div><div class="line">   String jobManagerOption = commandLine.getOptionValue(ADDRESS_OPTION.getOpt(), <span class="keyword">null</span>);</div><div class="line">   <span class="keyword">boolean</span> yarnJobManager = ID.equals(jobManagerOption);</div><div class="line">   <span class="keyword">boolean</span> yarnAppId = commandLine.hasOption(APPLICATION_ID.getOpt());</div><div class="line">   <span class="keyword">return</span> yarnJobManager || yarnAppId || loadYarnPropertiesFile(commandLine, configuration) != <span class="keyword">null</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上面可以看出如果用户传入了 <code>-m</code>参数或者<code>application id</code>或者配置了yarn properties 文件，则启动yarn cluster模式，否则是Standalone模式的集群</p>
<h5 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h5><p>flink通过<code>YarnClusterDescriptor</code>来描述yarn集群的部署配置，具体对应的配置文件为<code>flink-conf.yaml</code>，通过下面这段逻辑触发集群部署：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//AbstractYarnClusterDescriptor line372</span></div><div class="line"><span class="comment">/**</span></div><div class="line"> * This method will block until the ApplicationMaster/JobManager have been</div><div class="line"> * deployed on YARN.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">protected</span> YarnClusterClient <span class="title">deployInternal</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div></pre></td></tr></table></figure>
<p>大致列下过程：</p>
<ul>
<li>check yarn 集群队列资源是否满足请求</li>
<li>设置 AM Context、启动命令、submission context</li>
<li>如果开启高可用模式【通过反射调用 submission context 的两个方法修改属性】 keepContainersMethod    attemptFailuresValidityIntervalMethod 【和 Hadoop 的版本有关】第一个属性表示应用重试时是否保留 AM container，第二个属性表示 指定 间隔时间之内应用允许失败重启的次数</li>
<li>上传 用户 jar、flink-conf.yaml、lib 目录下所有的 jar 包、logback log4j配置文件 到 HDFS</li>
<li>通过 yarn client submit am context</li>
<li>将yarn client 及相关配置封装成 YarnClusterClient 返回</li>
</ul>
<p>真正在 AM 中运行的主类是 <code>YarnApplicationMasterRunner</code>，它的 <code>run</code>方法做了如下工作：</p>
<ul>
<li>启动JobManager ActorSystem</li>
<li>启动 flink ui</li>
<li>启动<code>YarnFlinkResourceManager</code>来负责与yarn的ResourceManager交互，管理yarn资源</li>
<li>启动 actor System supervise 进程</li>
</ul>
<p>到这里 JobManager 已经启动起来，那么 TaskManager是什么时候起动的呢？</p>
<p>在 <code>YarnFlinkResourceManager</code>启动的时候会预先执行一段逻辑【Akka actor的preStart方法】：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preStart</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="comment">// we start our leader retrieval service to make sure we get informed</span></div><div class="line">        <span class="comment">// about JobManager leader changes</span></div><div class="line">        leaderRetriever.start(<span class="keyword">new</span> LeaderRetrievalListener() &#123;</div><div class="line"></div><div class="line">		    <span class="meta">@Override</span></div><div class="line">		    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">notifyLeaderAddress</span><span class="params">(String leaderAddress, UUID leaderSessionID)</span> </span>&#123;</div><div class="line">		        self().tell(</div><div class="line">						<span class="keyword">new</span> NewLeaderAvailable(leaderAddress, leaderSessionID),</div><div class="line">						ActorRef.noSender());</div><div class="line">		    &#125;</div></pre></td></tr></table></figure>
<p>这段逻辑会先尝试获取 JobManager 的地址并给自己发送一个路由消息<code>NewLeaderAvailable</code>，然后<code>YarnFlinkResourceManager</code>会把自己注册到 <code>JobManager</code> 中，接着<code>JobManager</code>会发送一个回调命令：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//JobManager line358</span></div><div class="line">sender ! decorateMessage(<span class="keyword">new</span> <span class="type">RegisterResourceManagerSuccessful</span>(self, taskManagerResources))</div></pre></td></tr></table></figure>
<p>接着会触发这样一段逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//FlinkResourceManager line555</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">checkWorkersPool</span><span class="params">()</span> </span>&#123;</div><div class="line">   <span class="keyword">int</span> numWorkersPending = getNumWorkerRequestsPending();</div><div class="line">   <span class="keyword">int</span> numWorkersPendingRegistration = getNumWorkersPendingRegistration();</div><div class="line"></div><div class="line">   <span class="comment">// sanity checks</span></div><div class="line">   Preconditions.checkState(numWorkersPending &gt;= <span class="number">0</span>,</div><div class="line">      <span class="string">"Number of pending workers should never be below 0."</span>);</div><div class="line">   Preconditions.checkState(numWorkersPendingRegistration &gt;= <span class="number">0</span>,</div><div class="line">      <span class="string">"Number of pending workers pending registration should never be below 0."</span>);</div><div class="line"></div><div class="line">   <span class="comment">// see how many workers we want, and whether we have enough</span></div><div class="line">   <span class="keyword">int</span> allAvailableAndPending = startedWorkers.size() +</div><div class="line">      numWorkersPending + numWorkersPendingRegistration;</div><div class="line"></div><div class="line">   <span class="keyword">int</span> missing = designatedPoolSize - allAvailableAndPending;</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (missing &gt; <span class="number">0</span>) &#123;</div><div class="line">      requestNewWorkers(missing);</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>将所有的 TS 起动起来，这样一个 flink 集群便构建出来了。下面附图解释下这个流程：</p>
<img src="/2016/12/03/Flink基本组件和逻辑计划/flink-cluster-start-flow.png" alt="flink-cluster-start-flow" title="flink-cluster-start-flow">
<ol>
<li>flink cli 解析本地环境配置，启动 <code>ApplicationMaster</code></li>
<li>在 <code>ApplicationMaster</code> 中启动 <code>JobManager</code></li>
<li>在 <code>ApplicationMaster</code> 中启动<code>YarnFlinkResourceManager</code></li>
<li><code>YarnFlinkResourceManager</code>给<code>JobManager</code>发送注册信息</li>
<li><code>YarnFlinkResourceManager</code>注册成功后，<code>JobManager</code>给<code>YarnFlinkResourceManager</code>发送注册成功信息</li>
<li><code>YarnFlinkResourceManage</code>知道自己注册成功后像<code>ResourceManager</code>申请和<code>TaskManager</code>数量对等的 container</li>
<li>在container中启动<code>TaskManager</code></li>
<li><code>TaskManager</code>将自己注册到<code>JobManager</code>中</li>
</ol>
<p><em>接下来便是程序的提交和运行</em></p>
<p>程序在<code>CliFrontend</code>中被提交后，会触发这样一段逻辑</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ClusterClient 304</span></div><div class="line">	<span class="function"><span class="keyword">public</span> JobSubmissionResult <span class="title">run</span><span class="params">(PackagedProgram prog, <span class="keyword">int</span> parallelism)</span></span></div><div class="line">			<span class="keyword">throws</span> ProgramInvocationException</div><div class="line">	&#123;</div><div class="line">		Thread.currentThread().setContextClassLoader(prog.getUserCodeClassLoader());</div><div class="line">		...</div><div class="line">		<span class="keyword">else</span> <span class="keyword">if</span> (prog.isUsingInteractiveMode()) &#123;</div><div class="line">			LOG.info(<span class="string">"Starting program in interactive mode"</span>);</div><div class="line">			ContextEnvironmentFactory factory = <span class="keyword">new</span> ContextEnvironmentFactory(<span class="keyword">this</span>, prog.getAllLibraries(),</div><div class="line">					prog.getClasspaths(), prog.getUserCodeClassLoader(), parallelism, isDetached(),</div><div class="line">					prog.getSavepointPath());</div><div class="line">			ContextEnvironment.setAsContext(factory);</div><div class="line"></div><div class="line">			<span class="keyword">try</span> &#123;</div><div class="line">				<span class="comment">// invoke main method</span></div><div class="line">				prog.invokeInteractiveModeForExecution();</div><div class="line">				...</div><div class="line">			&#125;</div><div class="line">			<span class="keyword">finally</span> &#123;</div><div class="line">				ContextEnvironment.unsetContext();</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">else</span> &#123;</div><div class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"PackagedProgram does not have a valid invocation mode."</span>);</div><div class="line">		&#125;</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<p>注意到有一段<code>prog.invokeInteractiveModeForExecution()</code>，这是客户端生成初步逻辑计划的核心逻辑，下面将详细介绍</p>
<h3 id="客户端逻辑计划"><a href="#客户端逻辑计划" class="headerlink" title="客户端逻辑计划"></a>客户端逻辑计划</h3><p>上面提到<code>prog.invokeInteractiveModeForExecution()</code>这段逻辑会触发客户端逻辑计划的生成，那么是怎样一个过程呢？其实这里只是调用了用户jar包的主函数，真正的触发生成过程由用户代码的执行来完成。例如用户写了这样一段 flink 代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">object FlinkDemo extends App with Logging&#123;</div><div class="line">  <span class="function">override def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>=&#123;</div><div class="line">    val properties = <span class="keyword">new</span> Properties</div><div class="line">    properties.setProperty(<span class="string">"bootstrap.servers"</span>, DemoConfig.kafkaBrokerList)</div><div class="line"></div><div class="line"> properties.setProperty(<span class="string">"zookeeper.connect"</span>,<span class="string">"host01:2181,host02:2181,host03:2181/kafka08"</span>)</div><div class="line">    properties.setProperty(<span class="string">"group.id"</span>, <span class="string">"flink-demo-waimai-e"</span>)</div><div class="line"></div><div class="line">    val env = StreamExecutionEnvironment.getExecutionEnvironment</div><div class="line">    env.enableCheckpointing(<span class="number">5000L</span>, CheckpointingMode.EXACTLY_ONCE) <span class="comment">//checkpoint every 5 seconds.</span></div><div class="line">    val stream = env.addSource(<span class="keyword">new</span> FlinkKafkaConsumer08[String](<span class="string">"log.waimai_e"</span>, <span class="keyword">new</span> SimpleStringSchema, properties)).setParallelism(<span class="number">2</span>)</div><div class="line">    val counts = stream.name(<span class="string">"log.waimai_e"</span>).map(toPoiIdTuple(_)).filter(_._2 != <span class="keyword">null</span>)</div><div class="line">      .keyBy(<span class="number">0</span>)</div><div class="line">      .timeWindow(Time.seconds(<span class="number">5</span>))</div><div class="line">      .sum(<span class="number">1</span>)</div><div class="line"></div><div class="line">    counts.addSink(sendToKafka(_))</div><div class="line">    env.execute()</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>注意到这样一段<code>val env = StreamExecutionEnvironment.getExecutionEnvironment</code>，这段代码会获取客户端的环境配置，它首先会转到这样一段逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamExecutionEnvironment 1256</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> StreamExecutionEnvironment <span class="title">getExecutionEnvironment</span><span class="params">()</span> </span>&#123;</div><div class="line">   <span class="keyword">if</span> (contextEnvironmentFactory != <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">return</span> contextEnvironmentFactory.createExecutionEnvironment();</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="comment">// because the streaming project depends on "flink-clients" (and not the other way around)</span></div><div class="line">   <span class="comment">// we currently need to intercept the data set environment and create a dependent stream env.</span></div><div class="line">   <span class="comment">// this should be fixed once we rework the project dependencies</span></div><div class="line"></div><div class="line">   ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</div></pre></td></tr></table></figure>
<p><code>ExecutionEnvironment.getExecutionEnvironment();</code>获取环境的逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ExecutionEnvironment line1137</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutionEnvironment <span class="title">getExecutionEnvironment</span><span class="params">()</span> </span>&#123;</div><div class="line">   <span class="keyword">return</span> contextEnvironmentFactory == <span class="keyword">null</span> ?</div><div class="line">         createLocalEnvironment() : contextEnvironmentFactory.createExecutionEnvironment();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里的<code>contextEnvironmentFactory</code>是一个静态成员，早在<code>ContextEnvironment.setAsContext(factory)</code>已经触发过初始化了，其中包含了如下的环境信息:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//ContextEnvironmentFactory line51</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">ContextEnvironmentFactory</span><span class="params">(ClusterClient client, List&lt;URL&gt; jarFilesToAttach,</span></span></div><div class="line">      List&lt;URL&gt; classpathsToAttach, ClassLoader userCodeClassLoader, <span class="keyword">int</span> defaultParallelism,</div><div class="line">      <span class="keyword">boolean</span> isDetached, String savepointPath)</div><div class="line">&#123;</div><div class="line">   <span class="keyword">this</span>.client = client;</div><div class="line">   <span class="keyword">this</span>.jarFilesToAttach = jarFilesToAttach;</div><div class="line">   <span class="keyword">this</span>.classpathsToAttach = classpathsToAttach;</div><div class="line">   <span class="keyword">this</span>.userCodeClassLoader = userCodeClassLoader;</div><div class="line">   <span class="keyword">this</span>.defaultParallelism = defaultParallelism;</div><div class="line">   <span class="keyword">this</span>.isDetached = isDetached;</div><div class="line">   <span class="keyword">this</span>.savepointPath = savepointPath;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其中的 client 就是上面生成的 <code>YarnClusterClient</code>，其它的意思较明显，就不多做解释了。</p>
<p>用户在执行<code>val env = StreamExecutionEnvironment.getExecutionEnvironment</code>这样一段逻辑后会得到一个<code>StreamContextEnvironment</code>，其中封装了 streaming 的一些执行配置 【buffer time out等】，另外保存了上面提到的 <code>ContextEnvironmen</code>t 的引用。</p>
<p>到这里关于 streaming 需要的执行环境信息已经设置完成。</p>
<h4 id="初步逻辑计划-StreamGraph-的生成"><a href="#初步逻辑计划-StreamGraph-的生成" class="headerlink" title="初步逻辑计划 StreamGraph 的生成"></a>初步逻辑计划 StreamGraph 的生成</h4><p>接下来用户代码执行到<code>val stream = env.addSource(new FlinkKafkaConsumer08</code>，这段逻辑实际会生成一个<code>DataStream</code>抽象，<code>DataStream</code>是flink关于streaming抽象的最核心抽象，后续所有的算子转换都会在<code>DataStream</code>上来完成，上面的<code>addSource</code>操作会触发下面这段逻辑:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> &lt;OUT&gt; <span class="function">DataStreamSource&lt;OUT&gt; <span class="title">addSource</span><span class="params">(SourceFunction&lt;OUT&gt; function, String sourceName, TypeInformation&lt;OUT&gt; typeInfo)</span> </span>&#123;</div><div class="line"></div><div class="line">   <span class="keyword">if</span>(typeInfo == <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">if</span> (function <span class="keyword">instanceof</span> ResultTypeQueryable) &#123;</div><div class="line">         typeInfo = ((ResultTypeQueryable&lt;OUT&gt;) function).getProducedType();</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">         <span class="keyword">try</span> &#123;</div><div class="line">            typeInfo = TypeExtractor.createTypeInfo(</div><div class="line">                  SourceFunction.class,</div><div class="line">                  function.getClass(), <span class="number">0</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</div><div class="line">         &#125; <span class="keyword">catch</span> (<span class="keyword">final</span> InvalidTypesException e) &#123;</div><div class="line">            typeInfo = (TypeInformation&lt;OUT&gt;) <span class="keyword">new</span> MissingTypeInfo(sourceName, e);</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">boolean</span> isParallel = function <span class="keyword">instanceof</span> ParallelSourceFunction;</div><div class="line"></div><div class="line">   clean(function);</div><div class="line">   StreamSource&lt;OUT, ?&gt; sourceOperator;</div><div class="line">   <span class="keyword">if</span> (function <span class="keyword">instanceof</span> StoppableFunction) &#123;</div><div class="line">      sourceOperator = <span class="keyword">new</span> StoppableStreamSource&lt;&gt;(cast2StoppableSourceFunction(function));</div><div class="line">   &#125; <span class="keyword">else</span> &#123;</div><div class="line">      sourceOperator = <span class="keyword">new</span> StreamSource&lt;&gt;(function);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">return</span> <span class="keyword">new</span> DataStreamSource&lt;&gt;(<span class="keyword">this</span>, typeInfo, sourceOperator, isParallel, sourceName);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>简要总结下上面的逻辑：</p>
<ul>
<li>获取数据源 source 的 output 信息 TypeInformation</li>
<li>生成 StreamSource sourceOperator</li>
<li>生成 DataStreamSource【封装了 sourceOperator】，并返回</li>
<li>将 StreamTransformation 添加到算子列表 transformations 中【只有 转换 transform 操作才会添加算子，其它都只是暂时做了 transformation 的叠加封装】</li>
<li>后续会在 DataStream 上做操作</li>
</ul>
<p>该输出<code>DataStreamSource</code>继承自<code>SingleOutputStreamOperator</code>具体的继承关系如下：</p>
<img src="/2016/12/03/Flink基本组件和逻辑计划/flink-datastream-extend.png" alt="flink-datastream-extend" title="flink-datastream-extend">
<p>而生成的 StreamSource operator 走的是另一套继承接口：</p>
<img src="/2016/12/03/Flink基本组件和逻辑计划/stream-operator-extend.png" alt="stream-operator-extend" title="stream-operator-extend">
<p>DataStreamSource 是一个 DataStream <strong>数据流</strong>抽象，StreamSource 是一个 StreamOperator <strong>算子</strong>抽象，在 flink 中一个 DataStream 封装了一次数据流转换，一个 StreamOperator 封装了一个函数接口，比如 map、reduce、keyBy等。<em>关于算子的介绍会另起一节：flink算子的声明周期</em></p>
<p>可以看到在 DataStream 上可以进行一系列的操作(map filter 等)，来看一个常规操作比如 map 会发生什么：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//DataStream line503</span></div><div class="line"><span class="keyword">public</span> &lt;R&gt; <span class="function">SingleOutputStreamOperator&lt;R&gt; <span class="title">map</span><span class="params">(MapFunction&lt;T, R&gt; mapper)</span> </span>&#123;</div><div class="line"></div><div class="line">   TypeInformation&lt;R&gt; outType = TypeExtractor.getMapReturnTypes(clean(mapper), getType(),</div><div class="line">         Utils.getCallLocationName(), <span class="keyword">true</span>);</div><div class="line"></div><div class="line">   <span class="keyword">return</span> transform(<span class="string">"Map"</span>, outType, <span class="keyword">new</span> StreamMap&lt;&gt;(clean(mapper)));</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>一个map操作会触发一次 transform，那么transform做了什么工作呢？</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//DataStream line1020</span></div><div class="line"><span class="meta">@PublicEvolving</span></div><div class="line"><span class="keyword">public</span> &lt;R&gt; <span class="function">SingleOutputStreamOperator&lt;R&gt; <span class="title">transform</span><span class="params">(String operatorName, TypeInformation&lt;R&gt; outTypeInfo, OneInputStreamOperator&lt;T, R&gt; operator)</span> </span>&#123;</div><div class="line"></div><div class="line">   <span class="comment">// read the output type of the input Transform to coax out errors about MissingTypeInfo</span></div><div class="line">   transformation.getOutputType();</div><div class="line"></div><div class="line">   OneInputTransformation&lt;T, R&gt; resultTransform = <span class="keyword">new</span> OneInputTransformation&lt;&gt;(</div><div class="line">         <span class="keyword">this</span>.transformation,</div><div class="line">         operatorName,</div><div class="line">         operator,</div><div class="line">         outTypeInfo,</div><div class="line">         environment.getParallelism());</div><div class="line"></div><div class="line">   <span class="meta">@SuppressWarnings</span>(&#123; <span class="string">"unchecked"</span>, <span class="string">"rawtypes"</span> &#125;)</div><div class="line">   SingleOutputStreamOperator&lt;R&gt; returnStream = <span class="keyword">new</span> SingleOutputStreamOperator(environment, resultTransform);</div><div class="line"></div><div class="line">   getExecutionEnvironment().addOperator(resultTransform);</div><div class="line"></div><div class="line">   <span class="keyword">return</span> returnStream;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这一步生成了一个 <code>StreamTransformation</code>并以此作为成员变量封装成另一个 DataStream 返回，<code>StreamTransformation</code>是 flink关于数据流转换的核心抽象，只有需要 transform 的流才会生成新的DataStream 算子，后面会详细解释，注意上面有这一行<code>getExecutionEnvironment().addOperator(resultTransform)</code>flink会将transformation维护起来：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamExecutionEnvironment line 1237</span></div><div class="line"><span class="meta">@Internal</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addOperator</span><span class="params">(StreamTransformation&lt;?&gt; transformation)</span> </span>&#123;</div><div class="line">   Preconditions.checkNotNull(transformation, <span class="string">"transformation must not be null."</span>);</div><div class="line">   <span class="keyword">this</span>.transformations.add(transformation);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>所以，用户的一连串操作 map join等实际上在 DataStream 上做了转换，并且flink将这些 <code>StreamTransformation</code> 维护起来，一直到最后，用户执行 <code>env.execute()</code>这样一段逻辑，StreamGraph 的构建才算真正开始…</p>
<p>用户在执行<code>env.execute()</code>会触发这样一段逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamContextEnvironment line51   </span></div><div class="line"><span class="function"><span class="keyword">public</span> JobExecutionResult <span class="title">execute</span><span class="params">(String jobName)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">      Preconditions.checkNotNull(<span class="string">"Streaming Job name should not be null."</span>);</div><div class="line"></div><div class="line">      StreamGraph streamGraph = <span class="keyword">this</span>.getStreamGraph();</div><div class="line">      streamGraph.setJobName(jobName);</div><div class="line"></div><div class="line">      transformations.clear();</div><div class="line"></div><div class="line">      <span class="comment">// execute the programs</span></div><div class="line">      <span class="keyword">if</span> (ctx <span class="keyword">instanceof</span> DetachedEnvironment) &#123;</div><div class="line">         LOG.warn(<span class="string">"Job was executed in detached mode, the results will be available on completion."</span>);</div><div class="line">         ((DetachedEnvironment) ctx).setDetachedPlan(streamGraph);</div><div class="line">         <span class="keyword">return</span> DetachedEnvironment.DetachedJobExecutionResult.INSTANCE;</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">         <span class="keyword">return</span> ctx.getClient().runBlocking(streamGraph, ctx.getJars(), ctx.getClasspaths(), ctx.getUserCodeClassLoader(), ctx.getSavepointPath());</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这段代码做了两件事情：</p>
<ul>
<li>首先使用 <code>StreamGraphGenerator</code> 产生 StreamGraph</li>
<li>使用 Client 运行 stream graph</li>
</ul>
<p>那么<code>StreamGraphGenerator</code> 做了哪些操作呢？</p>
<p><code>StreamGraphGenerator</code>会依据添加算子时保存的 transformations 信息生成 job graph 中的节点，并创建节点连接，分流操作 如 union,select,split 不会添加边，只会创建虚拟节点或在上有节点添加 selector</p>
<p>这里会将 StreamTransformation 转换为 StreamNode，StreamNode 保存了算子的信息【会另外介绍】，如下图所示</p>
<p><img src="./transformation-to-node.png" width="535" height="300" alt="transformation-to-node.png" align="center"></p>
<p>到这里由 <code>StreamNode</code> 构成的 DAG 图 <code>StreamGraph</code>就生成了</p>
<p>不过 在提交给 client 的时候，flink 会做进一步的优化:</p>
<p> <code>StreamGraph</code> 将进一步转换为 <code>JobGraph</code>，这一步工作由 <code>StreamingJobGraphGenerator</code> 来完成，为什么要做这一步转换呢？主要因为有可以 chain 的算子，这里进一步将 StreamNode 转换为 JobVertex，主要工作是将可以 chain 的算子合并【这一步优化是默认打开的】，并设置资源，重试策略等，最终生成可以提交给 JobManager 的 JobGraph</p>
<h4 id="优化的逻辑计划-JobGraph-的生成"><a href="#优化的逻辑计划-JobGraph-的生成" class="headerlink" title="优化的逻辑计划 JobGraph 的生成"></a>优化的逻辑计划 JobGraph 的生成</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamingJobGraphGenerator line181</span></div><div class="line"><span class="function"><span class="keyword">private</span> List&lt;StreamEdge&gt; <span class="title">createChain</span><span class="params">(</span></span></div><div class="line">      Integer startNodeId,</div><div class="line">      Integer currentNodeId,</div><div class="line">      Map&lt;Integer, <span class="keyword">byte</span>[]&gt; hashes) &#123;</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (!builtVertices.contains(startNodeId)) &#123;</div><div class="line"></div><div class="line">      List&lt;StreamEdge&gt; transitiveOutEdges = <span class="keyword">new</span> ArrayList&lt;StreamEdge&gt;();</div><div class="line"></div><div class="line">      List&lt;StreamEdge&gt; chainableOutputs = <span class="keyword">new</span> ArrayList&lt;StreamEdge&gt;();</div><div class="line">      List&lt;StreamEdge&gt; nonChainableOutputs = <span class="keyword">new</span> ArrayList&lt;StreamEdge&gt;();</div><div class="line"></div><div class="line">      <span class="keyword">for</span> (StreamEdge outEdge : streamGraph.getStreamNode(currentNodeId).getOutEdges()) &#123;</div><div class="line">         <span class="keyword">if</span> (isChainable(outEdge)) &#123;</div><div class="line">            chainableOutputs.add(outEdge);</div><div class="line">         &#125; <span class="keyword">else</span> &#123;</div><div class="line">            nonChainableOutputs.add(outEdge);</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">for</span> (StreamEdge chainable : chainableOutputs) &#123;</div><div class="line">         transitiveOutEdges.addAll(createChain(startNodeId, chainable.getTargetId(), hashes));</div><div class="line">      &#125;</div><div class="line">     ...</div></pre></td></tr></table></figure>
<p>上面的方法是算子 chain 的核心操作，简要概括下：</p>
<ul>
<li>如果从此 start node 开始未生成过 JobVertex，则执行 chain逻辑，由于是递归操作，会先深度优先遍历，将源节点开始到第一个不可 chain 的 StreamNode 之间的算子做 chain 操作【先算叶子节点的 chain，依次往根节点计算】</li>
<li>line 207 遇到不可 chain 的边，开始深度遍历生成 JobVertex</li>
<li>line 216 将 StreamNode 的输入输出配置，包括序列化配置等设置到上面的 StreamingConfig 中，并在 vertexConfigs 中保存起来，如果是 新生成的 JobVertex，起对应的 StreamingConfig 会以 start node id 为 key 进行保存</li>
<li>transitiveOutEdges 保存的该节点下游所有的 non chain_able  edges，最终的方法会返回此数据结构</li>
<li>连接 start node 和所有的 transitiveOutEdges 【在输入 JobVertex 创建 IntermediateDataSet，partition类型为 pipeline，生成 JobEdge】</li>
<li>如果是新生成JobVertex，继续设置config，包括 chain start，所有物理输出，及直接逻辑输出、chained config等</li>
<li>如果不是新生成 JobVertex，直接chain configs</li>
</ul>
<p>这里总结下JobGraph的构建过程，见下图:</p>
<img src="/2016/12/03/Flink基本组件和逻辑计划/flink-job-graph-create.png" alt="flink-job-graph-create" title="flink-job-graph-create">
<p>大致过程总结如下：</p>
<ul>
<li>由<code>DataStream</code>上的操作生成<code>StreamTransformation</code>列表</li>
<li>从<code>StreamTransformation</code>的生成关系创建<code>StreamNode</code>和<code>StreamEdge</code></li>
<li>做算子chain，合并成 <code>JobVertex</code>，并生成 <code>JobEdge</code></li>
</ul>
<p>一个 JobVertex 代表一个逻辑计划的节点，就是 DAG 图上的顶点，有点类似于 Storm 的 bolt 或 spout，生成一个 JobVertex 的逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//StreamingJobGenerator line258</span></div><div class="line"><span class="function"><span class="keyword">private</span> StreamConfig <span class="title">createJobVertex</span><span class="params">(</span></span></div><div class="line">      Integer streamNodeId,</div><div class="line">      Map&lt;Integer, <span class="keyword">byte</span>[]&gt; hashes) &#123;</div><div class="line"></div><div class="line">   JobVertex jobVertex;</div><div class="line">   ...</div><div class="line">   JobVertexID jobVertexId = <span class="keyword">new</span> JobVertexID(hash);</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (streamNode.getInputFormat() != <span class="keyword">null</span>) &#123;</div><div class="line">      jobVertex = <span class="keyword">new</span> InputFormatVertex(</div><div class="line">            chainedNames.get(streamNodeId),</div><div class="line">            jobVertexId);</div><div class="line">      TaskConfig taskConfig = <span class="keyword">new</span> TaskConfig(jobVertex.getConfiguration());</div><div class="line">      taskConfig.setStubWrapper(<span class="keyword">new</span> UserCodeObjectWrapper&lt;Object&gt;(streamNode.getInputFormat()));</div><div class="line">   &#125; <span class="keyword">else</span> &#123;</div><div class="line">      jobVertex = <span class="keyword">new</span> JobVertex(</div><div class="line">            chainedNames.get(streamNodeId),</div><div class="line">            jobVertexId);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   jobVertex.setInvokableClass(streamNode.getJobVertexClass());</div><div class="line"></div><div class="line">   ...</div><div class="line"></div><div class="line">   <span class="keyword">return</span> <span class="keyword">new</span> StreamConfig(jobVertex.getConfiguration());</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><em>这里有两段逻辑值得注意，第一是数据源节点的判断，第二是运行时执行类 InvokableClass 的设置</em></p>
<p><code>streamNode.getInputFormat()</code>是判断是否是数据源节点的逻辑，如果是数据源节点，这里会将用户代码【这里为 InputFormat.class 的子类】设置进 JobVertex 的配置中，并在 JobManager 执行提交作业命令的时候做初始化，会在 Flink 物理计划生成一节介绍。</p>
<p><code>jobVertex.setInvokableClass</code>是设置运行时的执行类，通过这个类再调用用户定义的 operator，是 flink task 中真正被执行的类，具体会在 flink-task-runtime 一节中详细介绍。</p>
<p>至此 JobGraph 生成，并扔给 JobManager 执行😝</p>
]]></content>
    
    <summary type="html">
    
      Flink 源码，包括基本组件和客户端逻辑计划的生成
    
    </summary>
    
      <category term="Streaming" scheme="https://danny0405.github.io/categories/Streaming/"/>
    
    
      <category term="flink" scheme="https://danny0405.github.io/tags/flink/"/>
    
  </entry>
  
</feed>
